{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 1. Jiraì˜ ì´ìŠˆ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "> ğŸ”— 1. API í˜¸ì¶œì„ í†µí•´ Jira ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "- Jiraì˜ ì´ìŠˆë“¤ì„ APIì™€ JQLì„ í†µí•´ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (600325865.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    JIRA_USERNAME =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Jiraì—ì„œ ì´ìŠˆë“¤ì„ ê°€ì ¸ì™€ì„œ JSONL í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ì„ë² ë”©ìš©)\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List, Optional, Any\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "# --- ì„¤ì • ---\n",
    "JIRA_URL = \"https://jira.suprema.co.kr\"\n",
    "JIRA_USERNAME =\n",
    "JIRA_PASSWORD = \n",
    "JIRA_AUTH = (JIRA_USERNAME, JIRA_PASSWORD)\n",
    "# ìµœì¢… ê²°ê³¼ê°€ ì €ì¥ë  í´ë” ì´ë¦„\n",
    "OUTPUT_FOLDER = \"jira_issues_output\" # ì €ì¥ í´ë” ì´ë¦„ì„ ë” ëª…í™•í•˜ê²Œ ë³€ê²½\n",
    "\n",
    "# ê²€ìƒ‰í•  JQL ì¿¼ë¦¬\n",
    "JQL_QUERY = 'project = \"COMMONR\" AND issuetype = \"Test\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_jira_issue_keys(jql):\n",
    "    \"\"\"JQLë¡œ ëª¨ë“  ì´ìŠˆë¥¼ ê²€ìƒ‰í•˜ì—¬ ì´ìŠˆ í‚¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    all_issue_keys = []\n",
    "    start_at = 0\n",
    "    max_results = 100\n",
    "\n",
    "    print(f\"JQLë¡œ ì´ìŠˆ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤: {jql}\")\n",
    "\n",
    "    while True:\n",
    "        url = f\"{JIRA_URL}/rest/api/2/search\"\n",
    "        headers = {\"Accept\": \"application/json\"}\n",
    "        params = {\n",
    "            'jql': jql,\n",
    "            'fields': 'key',\n",
    "            'startAt': start_at,\n",
    "            'maxResults': max_results\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, auth=JIRA_AUTH)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            issues_on_page = data.get('issues', [])\n",
    "            \n",
    "            if not issues_on_page:\n",
    "                break\n",
    "            \n",
    "            keys_on_page = [issue['key'] for issue in issues_on_page]\n",
    "            all_issue_keys.extend(keys_on_page)\n",
    "            \n",
    "            start_at += len(issues_on_page)\n",
    "            print(f\"  -> í˜„ì¬ê¹Œì§€ {len(all_issue_keys)} / {data['total']} ê°œ ì´ìŠˆ í‚¤ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤...\")\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Jira ì´ìŠˆ ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "            \n",
    "    return all_issue_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 2. JSON íŒŒì¼ ì—´ ì •ì œ\n",
    "> ğŸ”— 2. JSON íŒŒì¼ì„ ì„ë² ë”© ëª¨ë¸ì— ì„ë² ë”©í•˜ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ì €ì¥\n",
    "- Jiraì˜ ì´ìŠˆë¥¼ ê°€ì ¸ì™€ì„œ ì„ë² ë”© ë° langchainì— ê°€ê³µí•˜ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_embedding_format(issue_key: str) -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    í•˜ë‚˜ì˜ ì´ìŠˆ í‚¤ì— ëŒ€í•œ ëª¨ë“  ì •ë³´ë¥¼ Jira APIë¥¼ í†µí•´ ê°€ì ¸ì™€ì„œ\n",
    "    ì„ë² ë”© ë° ChromaDB ì €ì¥ì— ìµœì í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ã…í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        issue_key (str): Jira ì´ìŠˆ í‚¤\n",
    "        \n",
    "    Returns:\n",
    "        Optional[List[Dict[str, Any]]]: ì„ë² ë”©ìš© ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        ê° ê°ì²´ëŠ” {'id', 'document', 'metadata'} êµ¬ì¡°\n",
    "    \"\"\"\n",
    "    url = f\"{JIRA_URL}/rest/api/2/issue/{issue_key}\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, auth=JIRA_AUTH)\n",
    "        response.raise_for_status()\n",
    "        issue_data = response.json()\n",
    "        \n",
    "        if not issue_data:\n",
    "            return None\n",
    "        \n",
    "        # ì´ìŠˆ ë°ì´í„° ì¶”ì¶œ\n",
    "        fields = issue_data.get('fields', {})\n",
    "        description = fields.get('description', '')\n",
    "        custom_field_10004 = fields.get('customfield_10004', {})\n",
    "        steps_list = custom_field_10004.get('steps', [])\n",
    "        \n",
    "        embedding_objects = []\n",
    "        \n",
    "        # ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ë³„ë¡œ ì„ë² ë”© ê°ì²´ ìƒì„±\n",
    "        if isinstance(steps_list, list):\n",
    "            for item in steps_list:\n",
    "                if isinstance(item, dict):\n",
    "                    index = item.get('index', '')\n",
    "                    step = item.get('step', '')\n",
    "                    data_item = item.get('data', '')\n",
    "                    expected_result = item.get('result', '')\n",
    "                    \n",
    "                    # page_content: test, step, data, expected resultë§Œ\n",
    "                    content_parts = []\n",
    "                    if step:\n",
    "                        content_parts.append(f\"Test Step: {step}\")\n",
    "                    if data_item:\n",
    "                        content_parts.append(f\"Test Data: {data_item}\")\n",
    "                    if expected_result:\n",
    "                        content_parts.append(f\"Expected Result: {expected_result}\")\n",
    "                    \n",
    "                    if content_parts:\n",
    "                        step_object = {\n",
    "                            \"id\": f\"{issue_key}_step_{index}\",\n",
    "                            \"document\": \"\\n\".join(content_parts),  # ChromaDB ìš©ì–´ ì‚¬ìš©\n",
    "                            \"metadata\": {\n",
    "                                \"issue_key\": issue_key,\n",
    "                                \"step_index\": str(index),  # ChromaDBëŠ” ë¬¸ìì—´ ì„ í˜¸\n",
    "                                \"source\": \"jira_test_step\"  # ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„ìš©\n",
    "                            }\n",
    "                        }\n",
    "                        embedding_objects.append(step_object)\n",
    "        \n",
    "        return embedding_objects\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"'{issue_key}'ì˜ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_save_file(json_data,issue_key) : \n",
    "    #1. ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ìƒì„±\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    print(f\" {issue_key} ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "    print(f\"ì €ì¥ í´ë”: '{os.path.abspath(OUTPUT_FOLDER)}'\")\n",
    "\n",
    "    #2. json íŒŒì¼ë¡œ ì €ì¥ì¥\n",
    "    try:\n",
    "        output_filepath = os.path.join(OUTPUT_FOLDER, f\"{issue_key}.json\")\n",
    "        with open(output_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "        return True\n",
    "    except IOError as e:\n",
    "        print(f\"'{output_filepath}' íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 3.JSON íŒŒì¼ ì„ë² ë”© ëª¨ë¸ì„ í†µí•´ ì„ë² ë”©\n",
    "> ğŸ”— JSON íŒŒì¼ì„ ì„ë² ë”© ëª¨ë¸ì„ í†µí•´ì„œ ì„ë² ë”©\n",
    "- e5-multilingual ì„ë² ë”© ëª¨ë¸ì„ í†µí•´ì„œ ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "def embed_jira_documents_with_e5(jira_folder_path: str = \"jira_issues_output\",\n",
    "                                model_name: str = \"intfloat/multilingual-e5-large\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    jira_issues_output í´ë”ì˜ JSON íŒŒì¼ë“¤ì„ ì½ì–´ì„œ E5 ëª¨ë¸ë¡œ ì„ë² ë”©í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        jira_folder_path (str): JIRA JSON íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "        model_name (str): ì‚¬ìš©í•  E5 ëª¨ë¸ëª…\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: LangChainìš©ìœ¼ë¡œ ìµœì í™”ëœ ì„ë² ë”© ê°ì²´ë“¤\n",
    "            ê° ê°ì²´ëŠ” {'id', 'page_content', 'metadata', 'embedding'} êµ¬ì¡°\n",
    "    \"\"\"\n",
    "    # 1. JSON íŒŒì¼ ì½ê¸°\n",
    "    if not os.path.exists(jira_folder_path):\n",
    "        raise FileNotFoundError(f\"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jira_folder_path}\")\n",
    "    \n",
    "    json_files = [f for f in os.listdir(jira_folder_path) if f.endswith('.json')]\n",
    "    if not json_files:\n",
    "        raise ValueError(f\"í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {jira_folder_path}\")\n",
    "    \n",
    "    all_documents = []\n",
    "    for json_file in json_files:\n",
    "        file_path = os.path.join(jira_folder_path, json_file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                all_documents.extend(data)\n",
    "            else:\n",
    "                all_documents.append(data)\n",
    "    \n",
    "    # 2. LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì˜ˆì™¸ì²˜ë¦¬ í¬í•¨)\n",
    "    embedding_objects = []\n",
    "    for doc in all_documents:\n",
    "        # í•„ìˆ˜ í‚¤ ì²´í¬ ë° ì˜ˆì™¸ì²˜ë¦¬\n",
    "        if not doc or 'id' not in doc or 'document' not in doc or 'metadata' not in doc:\n",
    "            continue  # ë¹ˆ ê°ì²´ë‚˜ í•„ìˆ˜ í‚¤ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°\n",
    "            \n",
    "        if not doc['document'].strip():  # ë¹ˆ ë¬¸ì„œë„ ê±´ë„ˆë›°ê¸°\n",
    "            continue\n",
    "            \n",
    "        embedding_obj = {\n",
    "            'id': doc['id'],\n",
    "            'page_content': doc['document'],\n",
    "            'metadata': doc['metadata']\n",
    "        }\n",
    "        embedding_objects.append(embedding_obj)\n",
    "    \n",
    "    # 3. E5 ëª¨ë¸ ë¡œë“œ ë° ì„ë² ë”©\n",
    "    print(f\"E5 ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "    \n",
    "    # page_content ì¶”ì¶œí•˜ì—¬ ì„ë² ë”©\n",
    "    documents = [obj['page_content'] for obj in embedding_objects]\n",
    "    \n",
    "    print(f\"ì´ {len(documents)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì‹œì‘...\")\n",
    "    \n",
    "    prefixed_documents = [f\"passage: {doc}\" for doc in documents]\n",
    "    \n",
    "    embeddings = model.encode(\n",
    "        prefixed_documents,\n",
    "        batch_size=8,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    \n",
    "    print(f\"ì„ë² ë”© ì™„ë£Œ! ë²¡í„° ì°¨ì›: {embeddings.shape[1]}\")\n",
    "    \n",
    "    # 4. ì„ë² ë”© ê²°ê³¼ ì¶”ê°€\n",
    "    result_objects = []\n",
    "    for i, obj in enumerate(embedding_objects):\n",
    "        embedded_obj = obj.copy()\n",
    "        embedded_obj['embedding'] = embeddings[i].tolist()\n",
    "        result_objects.append(embedded_obj)\n",
    "    \n",
    "    return result_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 4. ë²¡í„° DBë¥¼ í†µí•´ì„œ ì €ì¥\n",
    "> ğŸ”— í•´ë‹¹ ì„ë² ë”©í•œ ê²ƒì„ ë²¡í„° DBë¥¼ í†µí•´ì„œ ì €ì¥\n",
    "- Chroma DBë¥¼ ì‚¬ìš©í•´ì„œ ì„ë² ë”© ê°’ ì €ì¥\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E5 ëª¨ë¸ ë¡œë”© ì¤‘: intfloat/multilingual-e5-large\n",
      "ì‚¬ìš© ë””ë°”ì´ìŠ¤: cpu\n",
      "ì´ 2632ê°œ ë¬¸ì„œ ì„ë² ë”© ì‹œì‘...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b83510d6b4a472a905b0200a3d848b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ë² ë”© ì™„ë£Œ! ë²¡í„° ì°¨ì›: 1024\n",
      "âœ… 2632ê°œ ë¬¸ì„œê°€ ChromaDB ì»¬ë ‰ì…˜ 'jira_test_cases'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "def save_embeddings_to_chroma(embedded_objects: List[Dict[str, Any]], \n",
    "    collection_name: str = \"jira_test_cases\",\n",
    "    persist_directory: str = \"./chroma_db\") -> chromadb.Collection:\n",
    "    \"\"\"\n",
    "    ì„ë² ë”©ëœ ê°ì²´ë“¤ì„ ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        embedded_objects (List[Dict[str, Any]]): ì„ë² ë”©ì´ í¬í•¨ëœ ê°ì²´ë“¤\n",
    "            ê° ê°ì²´ëŠ” {'id', 'page_content', 'metadata', 'embedding'} êµ¬ì¡°\n",
    "        collection_name (str): ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "        persist_directory (str): ChromaDB ë°ì´í„° ì €ì¥ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        chromadb.Collection: ìƒì„±ëœ ChromaDB ì»¬ë ‰ì…˜\n",
    "    \"\"\"\n",
    "    # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì˜êµ¬ ì €ì¥)\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    \n",
    "    # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±\n",
    "    try:\n",
    "        client.delete_collection(name=collection_name)\n",
    "        print(f\"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œë¨\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±\n",
    "    collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©\n",
    "    )\n",
    "    \n",
    "    # ë°ì´í„° ë¶„ë¦¬\n",
    "    ids = [obj['id'] for obj in embedded_objects]\n",
    "    documents = [obj['page_content'] for obj in embedded_objects]\n",
    "    metadatas = [obj['metadata'] for obj in embedded_objects]\n",
    "    embeddings = [obj['embedding'] for obj in embedded_objects]\n",
    "    \n",
    "    # ChromaDBì— ë°°ì¹˜ ì¶”ê°€\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        embeddings=embeddings\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… {len(embedded_objects)}ê°œ ë¬¸ì„œê°€ ChromaDB ì»¬ë ‰ì…˜ '{collection_name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {persist_directory}\")\n",
    "    \n",
    "    return collection\n",
    "\n",
    "embedded_data = embed_jira_documents_with_e5()\n",
    "collection = save_embeddings_to_chroma(embedded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 5-1. langchainì„ ì´ìš©í•œ êµ¬ì¶• with LM Studio\n",
    "> ğŸ”— langchainì„ ì´ìš©í•´ì„œ ì €ì¥í•œ ì„ë² ë”© ê°’ì„ Langchain, LM Studioì™€ ì—°ê³„í•˜ì—¬ ìµœëŒ€ì˜ ê°’ ë„ì¶œ\n",
    "- langchainì„ ì´ìš©í•˜ì—¬ chroma DB ê²°ê³¼ê°’ QA RAGë¡œ êµ¬í˜„\n",
    "- í•´ë‹¹ RAG LM Studio LLMê³¼ ì—°ë™í•˜ì—¬ ê¸°ëŒ€ê°’ì— ëŒ€í•œ ê²°ê³¼ê°’ ë„ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ 'jira_test_cases' ì—°ê²° ì™„ë£Œ\n",
      "âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: 2ê°œ\n",
      "ğŸš€ LangChain í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° í…ŒìŠ¤íŠ¸\n",
      "----------------------------------------\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì¤‘: Master Adminê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤‘ì—ì„œ master admin ì„¤ì • ê°¯ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì¤˜\n",
      "\n",
      "ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼:\n",
      "==================================================\n",
      "ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: Master Adminê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤‘ì—ì„œ master admin ì„¤ì • ê°¯ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì¤˜\n",
      "ğŸ“Š ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìˆ˜: 10ê°œ\n",
      "\n",
      "ğŸ’¡ ë¶„ì„ ê²°ê³¼:\n",
      "Error: LM Studio í†µì‹  ì˜¤ë¥˜ - HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=120)\n",
      "\n",
      "ğŸ“š ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤:\n",
      "\n",
      "1. COMMONR-380_step_1\n",
      "   Test Step: 1. Device> ê´€ë¦¬ì ì„¤ì •\n",
      "Test Data: 1. Master Password ì„¤ì •\n",
      "2. ì „ì²´ ê´€ë¦¬ì ì„¤ì •\n",
      "3. ì¥ì¹˜ ì„¤ì • ê´€ë¦¬ì ì„¤ì •\n",
      "4. ì‚¬ìš©ì ê´€ë¦¬ì ì„¤ì •\n",
      "Expected Result: 1. ì‚¬ìš©ìê°€ ì„ íƒí•œ ê´€ë¦¬ìë¡œ ì„¤ì •ë˜ì–´ì•¼ í•œë‹¤.\n",
      ">...\n",
      "\n",
      "2. COMMONR-218_step_5\n",
      "   Test Step: [Master Admin ì§€ì› ì‹ ê·œHW]\n",
      "1. Master Admin ì„¤ì •\n",
      "2. Secure Tamper: Enable ì„¤ì •\n",
      "3. Secure Tamper ë°œìƒ\n",
      "Test Data: UI ì§€ì›ëª¨ë¸\n",
      "\n",
      "â€» Device> Device Info> Macì„ ê¸¸...\n",
      "\n",
      "3. COMMONR-247_step_1\n",
      "   Test Step: 1. ì¥ì¹˜ ë‘ëŒ€ì´ìƒ ì„ íƒ> Batch Edit í´ë¦­\n",
      "2. ë‹¤ìˆ˜ì˜ ê´€ë¦¬ì(All/User/Config) ìµœëŒ€ë¡œ ì„¤ì • í›„ ì ìš©\n",
      "3. ì¥ì¹˜ìƒì„¸ì •ë³´ì°½ ì§„ì…\n",
      "4. ê´€ë¦¬ì í™•ì¸\n",
      "5. All/User/Config ê´€ë¦¬ìë¡œ ë©”ë‰´ì§„ì…ì‹œë„\n",
      "Test Data: > Ma...\n",
      "\n",
      "4. COMMONR-379_step_18\n",
      "   Test Step: [Door ìƒì„±]\n",
      "1. Door > Add Door > Door êµ¬ì„±\n",
      "2. Manual Lock ë™ì‘\n",
      "3. Admin Menu ë¡œê·¸ì¸ ì‹œë„(Step 2ì—ì„œ ë“±ë¡í•œ Lock Override) > Masterì¥ì¹˜ì— ì¸ì¦ ì‹œë„\n",
      "Test Data: 1. C...\n",
      "\n",
      "5. COMMONR-247_step_2\n",
      "   Test Step: 1. ì¥ì¹˜ ë‘ëŒ€ì´ìƒ ì„ íƒ> Batch Edit í´ë¦­\n",
      "2. All/User/Config ê´€ë¦¬ìë¥¼ 1ëª…ì”© ì„¤ì • í›„ ì ìš©\n",
      "3. ì¥ì¹˜ìƒì„¸ì •ë³´ì°½ ì§„ì…\n",
      "4. ê´€ë¦¬ì í™•ì¸\n",
      "5. All/User/Config ê´€ë¦¬ìë¡œ ë©”ë‰´ì§„ì…ì‹œë„\n",
      "Test Data: > Max ê´€ë¦¬...\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "ğŸš€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸\n",
      "----------------------------------------\n",
      "ğŸš€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘: ì¥ì¹˜ì— ì „ì²´ ê´€ë¦¬ì ì„¤ì •ì„ ê°•ì œí•  ìˆ˜ ìˆëŠ” Master Admin ê¸°ëŠ¥ì´ ìˆëŠ”ë° ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘ì„ í•´. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ë™ì‘ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì¡°ê±´ì´ ìˆì–´. ë²„ì „ì´ V1.4.0 ì´ìƒìœ¼ë¡œ ìƒì‚°ëœ ì œí’ˆì´ì–´ì•¼í•´. ì¡°ê±´ì— ë¶€í•©ë˜ëŠ” ì¥ì¹˜ì˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ í™”ë©´ì— Master Admin ì„¤ì •í™”ë©´ì´ í‘œì‹œê°€ ë¼. í•˜ì§€ë§Œ ë²„ì „ì´ V1.4.0 ì´í•˜ë¡œ ìƒì‚°ëœ ì œí’ˆì˜ ê²½ìš°ì—ëŠ” ì¥ì¹˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ ë©”ì¸í™”ë©´ì´ í‘œì‹œê°€ ë¼. ë²„ì „ì€ BS3ì˜ ì´ì „ ë²„ì „ë“¤ì„ ì°¸ê³ í•´ì„œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‘ì„±í•´ì¤˜.\n",
      "\n",
      "ğŸš€ ìƒì„± ê²°ê³¼:\n",
      "==================================================\n",
      "ğŸ“ ìš”êµ¬ì‚¬í•­: ì¥ì¹˜ì— ì „ì²´ ê´€ë¦¬ì ì„¤ì •ì„ ê°•ì œí•  ìˆ˜ ìˆëŠ” Master Admin ê¸°ëŠ¥ì´ ìˆëŠ”ë° ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘ì„ í•´. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ë™ì‘ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì¡°ê±´ì´ ìˆì–´. ë²„ì „ì´ V1.4.0 ì´ìƒìœ¼ë¡œ ìƒì‚°ëœ ì œí’ˆì´ì–´ì•¼í•´. ì¡°ê±´ì— ë¶€í•©ë˜ëŠ” ì¥ì¹˜ì˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ í™”ë©´ì— Master Admin ì„¤ì •í™”ë©´ì´ í‘œì‹œê°€ ë¼. í•˜ì§€ë§Œ ë²„ì „ì´ V1.4.0 ì´í•˜ë¡œ ìƒì‚°ëœ ì œí’ˆì˜ ê²½ìš°ì—ëŠ” ì¥ì¹˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ ë©”ì¸í™”ë©´ì´ í‘œì‹œê°€ ë¼. ë²„ì „ì€ BS3ì˜ ì´ì „ ë²„ì „ë“¤ì„ ì°¸ê³ í•´ì„œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‘ì„±í•´ì¤˜.\n",
      "ğŸ“Š ì°¸ê³ í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìˆ˜: 8ê°œ\n",
      "\n",
      "ğŸ¯ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\n",
      "Error: LM Studio í†µì‹  ì˜¤ë¥˜ - HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=120)\n",
      "\n",
      "==============================\n",
      "\n",
      "âœ… LangChain ê²°ê³¼ê°€ langchain_testcase_results_20250810_233713.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ LangChain ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ì´ 2ê°œì˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "# FutureWarning ë¬´ì‹œ\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "class LMStudioLLM(LLM):\n",
    "    \"\"\"LM Studioì™€ ì—°ë™í•˜ëŠ” LangChain í˜¸í™˜ LLM í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    base_url: str = \"http://127.0.0.1:1234/v1\"\n",
    "    model_name: str = \"qwen/qwen3-8b\"\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 2048\n",
    "    \n",
    "    def __init__(self, \n",
    "                 base_url: str = \"http://127.0.0.1:1234/v1\",\n",
    "                 model_name: str = \"qwen/qwen3-8b\",\n",
    "                 temperature: float = 0.1,\n",
    "                 max_tokens: int = 2048,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self._test_connection()\n",
    "    \n",
    "    def _test_connection(self):\n",
    "        \"\"\"LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/models\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                models = response.json()\n",
    "                print(f\"âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models.get('data', []))}ê°œ\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ LM Studio ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LM Studio ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"lm_studio\"\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": self.temperature,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            if stop:\n",
    "                payload[\"stop\"] = stop\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=30000\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            else:\n",
    "                return f\"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}\"\n",
    "\n",
    "\n",
    "class LangChainTestCaseSystem:\n",
    "    def __init__(self, \n",
    "                 persist_directory: str = \"./chroma_db\",\n",
    "                 collection_name: str = \"jira_test_cases\",\n",
    "                 embedding_model_name: str = \"intfloat/multilingual-e5-large\",\n",
    "                 lm_studio_url: str = \"http://127.0.0.1:1234/v1\",\n",
    "                 lm_studio_model: str = \"qwen/qwen3-8b\"):\n",
    "        \n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = collection_name\n",
    "        \n",
    "        # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (CPU ì‚¬ìš©)\n",
    "        model_kwargs = {'device': 'cpu', 'trust_remote_code': True}\n",
    "        encode_kwargs = {'normalize_embeddings': True, 'batch_size': 4}\n",
    "        \n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=embedding_model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs\n",
    "        )\n",
    "        \n",
    "        # ChromaDB ì—°ê²°\n",
    "        self.vectorstore = self._connect_to_chroma()\n",
    "        \n",
    "        # LM Studio LLM ì´ˆê¸°í™”\n",
    "        self.llm = LMStudioLLM(\n",
    "            base_url=lm_studio_url,\n",
    "            model_name=lm_studio_model,\n",
    "            temperature=0.1,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸°ìš© ì²´ì¸\n",
    "        self.search_chain = self._setup_search_chain()\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ìš© ì²´ì¸\n",
    "        self.generation_chain = self._setup_generation_chain()\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥ìš©\n",
    "        self.test_results = []\n",
    "    \n",
    "    def _connect_to_chroma(self) -> Chroma:\n",
    "        \"\"\"ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ì— ì—°ê²°\"\"\"\n",
    "        try:\n",
    "            vectorstore = Chroma(\n",
    "                collection_name=self.collection_name,\n",
    "                embedding_function=self.embeddings,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "            print(f\"âœ… ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ '{self.collection_name}' ì—°ê²° ì™„ë£Œ\")\n",
    "            return vectorstore\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _setup_search_chain(self) -> RetrievalQA:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ìš© ì²´ì¸ ì„¤ì •\"\"\"\n",
    "        search_prompt_template = PromptTemplate(\n",
    "            template=\"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ì°¾ì•„ì„œ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ê²€ìƒ‰ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤:\n",
    "{context}\n",
    "\n",
    "ì‚¬ìš©ì ìš”ì²­: {question}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ìš”ì²­ê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤ì„ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”\n",
    "2. ê° í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ ì´ìŠˆ í‚¤, í…ŒìŠ¤íŠ¸ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ìŠ¤í…, ì˜ˆìƒ ê²°ê³¼ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”\n",
    "3. ì´ìŠˆë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”\n",
    "4. ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        \n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever(\n",
    "                search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={\"score_threshold\": 0.6, \"k\": 10}\n",
    "            ),\n",
    "            chain_type_kwargs={\"prompt\": search_prompt_template},\n",
    "            return_source_documents=True\n",
    "        )\n",
    "    \n",
    "    def _setup_generation_chain(self) -> RetrievalQA:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ìš© ì²´ì¸ ì„¤ì •\"\"\"\n",
    "        generation_prompt_template = PromptTemplate(\n",
    "            template=\"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤ì„ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³ í•  ê¸°ì¡´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤:\n",
    "{context}\n",
    "\n",
    "ì‚¬ìš©ì ìš”ì²­: {question}\n",
    "\n",
    "ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‘ì„± ê°€ì´ë“œë¼ì¸:\n",
    "1. ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” êµ¬ì²´ì ì¸ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
    "2. í…ŒìŠ¤íŠ¸ ëª©ì , ì „ì œ ì¡°ê±´, í…ŒìŠ¤íŠ¸ ìŠ¤í…, ì˜ˆìƒ ê²°ê³¼ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”\n",
    "3. ê¸°ì¡´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ íŒ¨í„´ê³¼ í˜•ì‹ì„ ì°¸ê³ í•˜ë˜, ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "4. í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
    "5. Edge Caseë‚˜ ì˜ˆì™¸ ìƒí™©ë„ ê³ ë ¤í•´ì£¼ì„¸ìš”\n",
    "6. ê°€ëŠ¥í•˜ë‹¤ë©´ ì—¬ëŸ¬ ê°œì˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ í˜•ì‹:\n",
    "**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: [í…ŒìŠ¤íŠ¸ ì œëª©]**\n",
    "- **í…ŒìŠ¤íŠ¸ ëª©ì **: [ëª©ì  ì„¤ëª…]\n",
    "- **ì „ì œ ì¡°ê±´**: [ì‚¬ì „ ì¡°ê±´]\n",
    "- **í…ŒìŠ¤íŠ¸ ìŠ¤í…**:\n",
    "  1. [ìŠ¤í… 1]\n",
    "  2. [ìŠ¤í… 2]\n",
    "  ...\n",
    "- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: [í•„ìš”í•œ ë°ì´í„°]\n",
    "- **ì˜ˆìƒ ê²°ê³¼**: [ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼]\n",
    "\n",
    "ë‹µë³€:\"\"\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        \n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={\"k\": 8}\n",
    "            ),\n",
    "            chain_type_kwargs={\"prompt\": generation_prompt_template},\n",
    "            return_source_documents=True\n",
    "        )\n",
    "    \n",
    "    def find_test_cases(self, query: str, filters: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° ê¸°ëŠ¥\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì¤‘: {query}\")\n",
    "            \n",
    "            formatted_query = f\"query: {query}\"\n",
    "            response = self.search_chain({\"query\": formatted_query})\n",
    "            \n",
    "            # ì†ŒìŠ¤ ë¬¸ì„œ ì •ë¦¬\n",
    "            source_docs = []\n",
    "            for doc in response.get(\"source_documents\", []):\n",
    "                source_docs.append({\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata,\n",
    "                    \"issue_key\": doc.metadata.get(\"issue_key\", \"\"),\n",
    "                    \"step_index\": doc.metadata.get(\"step_index\", \"\")\n",
    "                })\n",
    "            \n",
    "            result = {\n",
    "                \"query\": query,\n",
    "                \"answer\": response[\"result\"],\n",
    "                \"found_test_cases\": source_docs,\n",
    "                \"total_found\": len(source_docs)\n",
    "            }\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            self._save_result(\"find_test_cases\", query, result)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            error_result = {\"query\": query, \"error\": error_msg}\n",
    "            self._save_result(\"find_test_cases\", query, error_result)\n",
    "            return error_result\n",
    "    \n",
    "    def generate_test_case(self, requirement: str) -> Dict[str, Any]:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ê¸°ëŠ¥\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸš€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘: {requirement}\")\n",
    "            \n",
    "            formatted_requirement = f\"query: {requirement}\"\n",
    "            response = self.generation_chain({\"query\": formatted_requirement})\n",
    "            \n",
    "            # ì°¸ê³ í•œ ì†ŒìŠ¤ ë¬¸ì„œë“¤\n",
    "            reference_docs = []\n",
    "            for doc in response.get(\"source_documents\", []):\n",
    "                reference_docs.append({\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata,\n",
    "                    \"issue_key\": doc.metadata.get(\"issue_key\", \"\"),\n",
    "                    \"step_index\": doc.metadata.get(\"step_index\", \"\")\n",
    "                })\n",
    "            \n",
    "            result = {\n",
    "                \"requirement\": requirement,\n",
    "                \"generated_test_case\": response[\"result\"],\n",
    "                \"reference_test_cases\": reference_docs,\n",
    "                \"reference_count\": len(reference_docs)\n",
    "            }\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            self._save_result(\"generate_test_case\", requirement, result)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            error_result = {\"requirement\": requirement, \"error\": error_msg}\n",
    "            self._save_result(\"generate_test_case\", requirement, error_result)\n",
    "            return error_result\n",
    "    \n",
    "    def _save_result(self, test_type: str, query: str, result: Any):\n",
    "        \"\"\"ê²°ê³¼ ì €ì¥\"\"\"\n",
    "        self.test_results.append({\n",
    "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "            \"framework\": \"langchain\",\n",
    "            \"test_type\": test_type,\n",
    "            \"query\": query,\n",
    "            \"result\": result\n",
    "        })\n",
    "    \n",
    "    def save_results_to_file(self, filename: str = None):\n",
    "        \"\"\"ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"langchain_testcase_results_{timestamp}.json\"\n",
    "        \n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.test_results, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"âœ… LangChain ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    def print_find_result(self, result: Dict[str, Any]):\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        print(f\"\\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "        print(\"=\" * 50)\n",
    "        if \"error\" in result:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {result['error']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {result['query']}\")\n",
    "        print(f\"ğŸ“Š ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìˆ˜: {result['total_found']}ê°œ\")\n",
    "        print(f\"\\nğŸ’¡ ë¶„ì„ ê²°ê³¼:\")\n",
    "        print(result['answer'])\n",
    "        \n",
    "        if result['found_test_cases']:\n",
    "            print(f\"\\nğŸ“š ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤:\")\n",
    "            for i, doc in enumerate(result['found_test_cases'][:5], 1):\n",
    "                issue_key = doc['issue_key']\n",
    "                step_idx = doc['step_index']\n",
    "                print(f\"\\n{i}. {issue_key}_step_{step_idx}\")\n",
    "                print(f\"   {doc['content'][:150]}...\")\n",
    "    \n",
    "    def print_generation_result(self, result: Dict[str, Any]):\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        print(f\"\\nğŸš€ ìƒì„± ê²°ê³¼:\")\n",
    "        print(\"=\" * 50)\n",
    "        if \"error\" in result:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {result['error']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ“ ìš”êµ¬ì‚¬í•­: {result['requirement']}\")\n",
    "        print(f\"ğŸ“Š ì°¸ê³ í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìˆ˜: {result['reference_count']}ê°œ\")\n",
    "        print(f\"\\nğŸ¯ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\")\n",
    "        print(result['generated_test_case'])\n",
    "    \n",
    "    def run_comprehensive_test(self):\n",
    "        \"\"\"ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸš€ LangChain í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° í…ŒìŠ¤íŠ¸ë“¤\n",
    "        find_queries = [\n",
    "            \"Master Adminê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤‘ì—ì„œ master admin ì„¤ì • ê°¯ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì¤˜\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"-\" * 40)\n",
    "        for query in find_queries:\n",
    "            result = self.find_test_cases(query)\n",
    "            self.print_find_result(result)\n",
    "            print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "        \n",
    "        # 2. í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ë“¤\n",
    "        generation_requirements = [\n",
    "            \"ì¥ì¹˜ì— ì „ì²´ ê´€ë¦¬ì ì„¤ì •ì„ ê°•ì œí•  ìˆ˜ ìˆëŠ” Master Admin ê¸°ëŠ¥ì´ ìˆëŠ”ë° ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘ì„ í•´. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ë™ì‘ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì¡°ê±´ì´ ìˆì–´. ë²„ì „ì´ V1.4.0 ì´ìƒìœ¼ë¡œ ìƒì‚°ëœ ì œí’ˆì´ì–´ì•¼í•´. ì¡°ê±´ì— ë¶€í•©ë˜ëŠ” ì¥ì¹˜ì˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ í™”ë©´ì— Master Admin ì„¤ì •í™”ë©´ì´ í‘œì‹œê°€ ë¼. í•˜ì§€ë§Œ ë²„ì „ì´ V1.4.0 ì´í•˜ë¡œ ìƒì‚°ëœ ì œí’ˆì˜ ê²½ìš°ì—ëŠ” ì¥ì¹˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ ë©”ì¸í™”ë©´ì´ í‘œì‹œê°€ ë¼. ë²„ì „ì€ BS3ì˜ ì´ì „ ë²„ì „ë“¤ì„ ì°¸ê³ í•´ì„œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‘ì„±í•´ì¤˜.\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nğŸš€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"-\" * 40)\n",
    "        for requirement in generation_requirements:\n",
    "            result = self.generate_test_case(requirement)\n",
    "            self.print_generation_result(result)\n",
    "            print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        self.save_results_to_file()\n",
    "        \n",
    "        print(f\"\\nğŸ‰ LangChain ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "        print(f\"ì´ {len(self.test_results)}ê°œì˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # LangChain í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    langchain_system = LangChainTestCaseSystem(\n",
    "        lm_studio_url=\"http://127.0.0.1:1234/v1\",\n",
    "        lm_studio_model=\"qwen/qwen3-8b\"\n",
    "    )\n",
    "    \n",
    "    # ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    langchain_system.run_comprehensive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 5-2. llamaindexì„ ì´ìš©í•œ êµ¬ì¶• with LM Studio\n",
    "> ğŸ”— llamaindexì„ ì´ìš©í•´ì„œ ì €ì¥í•œ ì„ë² ë”© ê°’ì„ Langchain, LM Studioì™€ ì—°ê³„í•˜ì—¬ ìµœëŒ€ì˜ ê°’ ë„ì¶œ\n",
    "- llamaindexì„ ì´ìš©í•˜ì—¬ chroma DB ê²°ê³¼ê°’ QA RAGë¡œ êµ¬í˜„\n",
    "- í•´ë‹¹ RAG LM Studio LLMê³¼ ì—°ë™í•˜ì—¬ ê¸°ëŒ€ê°’ì— ëŒ€í•œ ê²°ê³¼ê°’ ë„ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: 2ê°œ\n",
      "âœ… LM Studio LLM ì„¤ì • ì™„ë£Œ: http://127.0.0.1:1234/v1\n",
      "âœ… ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ 'jira_test_cases' ì—°ê²° ì™„ë£Œ\n",
      "âœ… LlamaIndex ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\n",
      "âœ… ê²€ìƒ‰ìš© ì¿¼ë¦¬ ì—”ì§„ ì„¤ì • ì™„ë£Œ\n",
      "âœ… ìƒì„±ìš© ì¿¼ë¦¬ ì—”ì§„ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ LlamaIndex í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "ğŸ” ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
      "----------------------------------------\n",
      "ğŸ” LlamaIndex ê³ ê¸‰ ê²€ìƒ‰ ì¤‘: Master Adminê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤‘ì—ì„œ master admin ì„¤ì • ê°¯ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì¤˜\n",
      "\n",
      "ğŸ” LlamaIndex ê²€ìƒ‰ ê²°ê³¼:\n",
      "==================================================\n",
      "ğŸ“ ê²€ìƒ‰ ì¿¼ë¦¬: Master Adminê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤‘ì—ì„œ master admin ì„¤ì • ê°¯ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì¤˜\n",
      "ğŸ“Š ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤: 20ê°œ\n",
      "ğŸ·ï¸ ê´€ë ¨ ì´ìŠˆ: 11ê°œ\n",
      "\n",
      "ğŸ¤– LLM ë¶„ì„ ê²°ê³¼:\n",
      "Error: LM Studio í†µì‹  ì˜¤ë¥˜ - HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=120)\n",
      "\n",
      "ğŸ“š ì´ìŠˆë³„ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\n",
      "\n",
      "ğŸ”— COMMONR-380:\n",
      "  1. (ì ìˆ˜: 0.892) Test Step: 1. Device> ê´€ë¦¬ì ì„¤ì •\n",
      "Test Data: 1. Master Password ì„¤ì •\n",
      "2. ì „ì²´ ê´€ë¦¬ì ì„¤ì •\n",
      "3. ì¥ì¹˜ ì„¤ì • ê´€ë¦¬ì ì„¤ì •\n",
      "4. ì‚¬ìš©ì ê´€ë¦¬ì ì„¤ì •\n",
      "Expected Result...\n",
      "  2. (ì ìˆ˜: 0.861) Test Step: 1. ê´€ë¦¬ì ì„¤ì •/ë¯¸ì„¤ì •\n",
      "2. ë©”ë‰´ ì§„ì… ìƒíƒœ > ì¸ì¦ \n",
      "3. ë©”ë‰´ ì§„ì… ì‹œë„ì™€ ë™ì‹œì— ì¸ì¦ ì‹œë„\n",
      "Expected Result: 1. ì„¤ì •ëœ ê¶Œí•œìœ¼ë¡œ ì¶œì…ë¬¸ì œì–´ê°€ ë˜ì–´ì•¼ í•œë‹¤.\n",
      "> ë©”ë‰´ ì§„ì… í›„ ...\n",
      "\n",
      "ğŸ”— COMMONR-218:\n",
      "  1. (ì ìˆ˜: 0.872) Test Step: [Master Admin ì§€ì› ì‹ ê·œHW]\n",
      "1. Master Admin ì„¤ì •\n",
      "2. Secure Tamper: Enable ì„¤ì •\n",
      "3. Secure Tamper ë°œìƒ\n",
      "Test Data: UI ì§€ì›ëª¨ë¸\n",
      "...\n",
      "  2. (ì ìˆ˜: 0.860) Test Step: [Master Admin ì§€ì› ì‹ ê·œHW]\n",
      "1. Secure Tamper: Enable ì„¤ì •\n",
      "2. Secure Tamper ë°œìƒ\n",
      "Test Data: UI ë¯¸ì§€ì›ëª¨ë¸ - ex. XP2\n",
      "Expected...\n",
      "\n",
      "ğŸ”— COMMONR-247:\n",
      "  1. (ì ìˆ˜: 0.872) Test Step: 1. ì¥ì¹˜ ë‘ëŒ€ì´ìƒ ì„ íƒ> Batch Edit í´ë¦­\n",
      "2. ë‹¤ìˆ˜ì˜ ê´€ë¦¬ì(All/User/Config) ìµœëŒ€ë¡œ ì„¤ì • í›„ ì ìš©\n",
      "3. ì¥ì¹˜ìƒì„¸ì •ë³´ì°½ ì§„ì…\n",
      "4. ê´€ë¦¬ì í™•ì¸\n",
      "5. All/User/Conf...\n",
      "  2. (ì ìˆ˜: 0.869) Test Step: 1. ì¥ì¹˜ ë‘ëŒ€ì´ìƒ ì„ íƒ> Batch Edit í´ë¦­\n",
      "2. All/User/Config ê´€ë¦¬ìë¥¼ 1ëª…ì”© ì„¤ì • í›„ ì ìš©\n",
      "3. ì¥ì¹˜ìƒì„¸ì •ë³´ì°½ ì§„ì…\n",
      "4. ê´€ë¦¬ì í™•ì¸\n",
      "5. All/User/Config ê´€...\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "ğŸš€ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸\n",
      "----------------------------------------\n",
      "ğŸš€ LlamaIndex ê³ ê¸‰ ìƒì„± ì¤‘: ì¥ì¹˜ì— ì „ì²´ ê´€ë¦¬ì ì„¤ì •ì„ ê°•ì œí•  ìˆ˜ ìˆëŠ” Master Admin ê¸°ëŠ¥ì´ ìˆëŠ”ë° ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘ì„ í•´. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ë™ì‘ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì¡°ê±´ì´ ìˆì–´. ë²„ì „ì´ V1.4.0 ì´ìƒìœ¼ë¡œ ìƒì‚°ëœ ì œí’ˆì´ì–´ì•¼í•´. ì¡°ê±´ì— ë¶€í•©ë˜ëŠ” ì¥ì¹˜ì˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ í™”ë©´ì— Master Admin ì„¤ì •í™”ë©´ì´ í‘œì‹œê°€ ë¼. í•˜ì§€ë§Œ ë²„ì „ì´ V1.4.0 ì´í•˜ë¡œ ìƒì‚°ëœ ì œí’ˆì˜ ê²½ìš°ì—ëŠ” ì¥ì¹˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ ë©”ì¸í™”ë©´ì´ í‘œì‹œê°€ ë¼. ë²„ì „ì€ BS3ì˜ ì´ì „ ë²„ì „ë“¤ì„ ì°¸ê³ í•´ì„œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‘ì„±í•´ì¤˜.\n",
      "\n",
      "ğŸš€ LlamaIndex ìƒì„± ê²°ê³¼:\n",
      "==================================================\n",
      "ğŸ“‹ ìš”êµ¬ì‚¬í•­: ì¥ì¹˜ì— ì „ì²´ ê´€ë¦¬ì ì„¤ì •ì„ ê°•ì œí•  ìˆ˜ ìˆëŠ” Master Admin ê¸°ëŠ¥ì´ ìˆëŠ”ë° ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘ì„ í•´. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ë™ì‘ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì¡°ê±´ì´ ìˆì–´. ë²„ì „ì´ V1.4.0 ì´ìƒìœ¼ë¡œ ìƒì‚°ëœ ì œí’ˆì´ì–´ì•¼í•´. ì¡°ê±´ì— ë¶€í•©ë˜ëŠ” ì¥ì¹˜ì˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ í™”ë©´ì— Master Admin ì„¤ì •í™”ë©´ì´ í‘œì‹œê°€ ë¼. í•˜ì§€ë§Œ ë²„ì „ì´ V1.4.0 ì´í•˜ë¡œ ìƒì‚°ëœ ì œí’ˆì˜ ê²½ìš°ì—ëŠ” ì¥ì¹˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ ë©”ì¸í™”ë©´ì´ í‘œì‹œê°€ ë¼. ë²„ì „ì€ BS3ì˜ ì´ì „ ë²„ì „ë“¤ì„ ì°¸ê³ í•´ì„œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‘ì„±í•´ì¤˜.\n",
      "ğŸ“Š ì°¸ì¡° ìë£Œ: 15ê°œ\n",
      "â­ ìƒì„± í’ˆì§ˆ ì ìˆ˜: 20/100\n",
      "ğŸ” ì°¸ì¡° ë¶„ì„: ë¶„ì„ëœ 15ê°œ ì°¸ì¡° ìë£Œì—ì„œ 1ê°œ ì´ìŠˆ íƒ€ì… ë°œê²¬\n",
      "\n",
      "ğŸ¯ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\n",
      "----------------------------------------\n",
      "Error: LM Studio í†µì‹  ì˜¤ë¥˜ - HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=120)\n",
      "\n",
      "==============================\n",
      "\n",
      "âœ… LlamaIndex ê²°ê³¼ê°€ llamaindex_testcase_results_20250810_234123.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ LlamaIndex ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ì´ 2ê°œì˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.llms import CustomLLM, CompletionResponse, LLMMetadata\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, LLMRerank\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "from typing import List, Dict, Any, Optional, Generator, Sequence\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "# FutureWarning ë¬´ì‹œ\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "class LMStudioLLM(CustomLLM):\n",
    "    \"\"\"LM Studioì™€ ì—°ë™í•˜ëŠ” LlamaIndexìš© ì»¤ìŠ¤í…€ LLM í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    model_name: str = \"qwen/qwen3-8b\"\n",
    "    base_url: str = \"http://127.0.0.1:1234/v1\"\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 2048\n",
    "    \n",
    "    def __init__(self, \n",
    "                 base_url: str = \"http://127.0.0.1:1234/v1\",\n",
    "                 model_name: str = \"qwen/qwen3-8b\",\n",
    "                 temperature: float = 0.1,\n",
    "                 max_tokens: int = 2048,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self._test_connection()\n",
    "    \n",
    "    def _test_connection(self):\n",
    "        \"\"\"LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/models\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                models = response.json()\n",
    "                print(f\"âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models.get('data', []))}ê°œ\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ LM Studio ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LM Studio ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        return LLMMetadata(\n",
    "            context_window=8192,\n",
    "            num_output=self.max_tokens,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "    \n",
    "    def complete(self, prompt: str, **kwargs) -> CompletionResponse:\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": self.temperature,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=30000\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return CompletionResponse(text=text)\n",
    "            else:\n",
    "                error_text = f\"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})\"\n",
    "                return CompletionResponse(text=error_text)\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_text = f\"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}\"\n",
    "            return CompletionResponse(text=error_text)\n",
    "    \n",
    "    def chat(self, messages: Sequence[ChatMessage], **kwargs) -> CompletionResponse:\n",
    "        formatted_messages = []\n",
    "        for msg in messages:\n",
    "            formatted_messages.append({\n",
    "                \"role\": msg.role.value if hasattr(msg.role, 'value') else str(msg.role),\n",
    "                \"content\": msg.content\n",
    "            })\n",
    "        \n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": formatted_messages,\n",
    "                \"temperature\": self.temperature,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=30000\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return CompletionResponse(text=text)\n",
    "            else:\n",
    "                error_text = f\"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})\"\n",
    "                return CompletionResponse(text=error_text)\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_text = f\"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}\"\n",
    "            return CompletionResponse(text=error_text)\n",
    "    \n",
    "    def stream_complete(self, prompt: str, **kwargs) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.complete(prompt, **kwargs)\n",
    "        yield response\n",
    "    \n",
    "    def stream_chat(self, messages: Sequence[ChatMessage], **kwargs) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.chat(messages, **kwargs)\n",
    "        yield response\n",
    "\n",
    "\n",
    "class LlamaIndexTestCaseSystem:\n",
    "    def __init__(self, \n",
    "                 persist_directory: str = \"./chroma_db\",\n",
    "                 collection_name: str = \"jira_test_cases\",\n",
    "                 embedding_model_name: str = \"intfloat/multilingual-e5-large\",\n",
    "                 lm_studio_url: str = \"http://127.0.0.1:1234/v1\",\n",
    "                 lm_studio_model: str = \"qwen/qwen3-8b\"):\n",
    "        \n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = collection_name\n",
    "        self.lm_studio_url = lm_studio_url\n",
    "        self.lm_studio_model = lm_studio_model\n",
    "        \n",
    "        # Global Settings ì„¤ì •\n",
    "        self._setup_global_settings(embedding_model_name)\n",
    "        \n",
    "        # ChromaDB ë²¡í„° ìŠ¤í† ì–´ ì—°ê²°\n",
    "        self.vector_store = self._connect_to_chroma()\n",
    "        \n",
    "        # ì¸ë±ìŠ¤ ìƒì„±\n",
    "        self.index = self._create_index()\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸°ìš© ì¿¼ë¦¬ ì—”ì§„\n",
    "        self.search_engine = self._setup_search_engine()\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ìš© ì¿¼ë¦¬ ì—”ì§„\n",
    "        self.generation_engine = self._setup_generation_engine()\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥ìš©\n",
    "        self.test_results = []\n",
    "    \n",
    "    def _setup_global_settings(self, embedding_model_name: str):\n",
    "        \"\"\"LlamaIndex Global Settings ì„¤ì •\"\"\"\n",
    "        # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (CPU ì‚¬ìš©)\n",
    "        Settings.embed_model = HuggingFaceEmbedding(\n",
    "            model_name=embedding_model_name,\n",
    "            device=\"cpu\",\n",
    "            trust_remote_code=True,\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # LM Studio LLM ì„¤ì •\n",
    "        Settings.llm = LMStudioLLM(\n",
    "            base_url=self.lm_studio_url,\n",
    "            model_name=self.lm_studio_model,\n",
    "            temperature=0.1,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… LM Studio LLM ì„¤ì • ì™„ë£Œ: {self.lm_studio_url}\")\n",
    "    \n",
    "    def _connect_to_chroma(self) -> ChromaVectorStore:\n",
    "        \"\"\"ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ì— ì—°ê²°\"\"\"\n",
    "        try:\n",
    "            chroma_client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            chroma_collection = chroma_client.get_collection(name=self.collection_name)\n",
    "            vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "            \n",
    "            print(f\"âœ… ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ '{self.collection_name}' ì—°ê²° ì™„ë£Œ\")\n",
    "            return vector_store\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_index(self) -> VectorStoreIndex:\n",
    "        \"\"\"ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¡œë¶€í„° ì¸ë±ìŠ¤ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            storage_context = StorageContext.from_defaults(vector_store=self.vector_store)\n",
    "            index = VectorStoreIndex.from_vector_store(\n",
    "                vector_store=self.vector_store,\n",
    "                storage_context=storage_context\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… LlamaIndex ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "            return index\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _setup_search_engine(self) -> RetrieverQueryEngine:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ìš© ì¿¼ë¦¬ ì—”ì§„ ì„¤ì •\"\"\"\n",
    "        # ê²€ìƒ‰ì— íŠ¹í™”ëœ ë¦¬íŠ¸ë¦¬ë²„ (ë” ë§ì€ ê²°ê³¼, ë‚®ì€ ì„ê³„ê°’)\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=self.index,\n",
    "            similarity_top_k=12\n",
    "        )\n",
    "        \n",
    "        # ê²€ìƒ‰ìš© í¬ìŠ¤íŠ¸í”„ë¡œì„¸ì„œ (ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë§Œ í•„í„°ë§)\n",
    "        postprocessors = [\n",
    "            SimilarityPostprocessor(similarity_cutoff=0.6)\n",
    "        ]\n",
    "        \n",
    "        query_engine = RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            node_postprocessors=postprocessors\n",
    "        )\n",
    "        \n",
    "        # ê²€ìƒ‰ìš© ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸\n",
    "        search_prompt = PromptTemplate(\n",
    "            \"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ë° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ì°¾ì•„ì„œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ê²€ìƒ‰ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤:\n",
    "{context_str}\n",
    "\n",
    "ì‚¬ìš©ì ê²€ìƒ‰ ìš”ì²­: {query_str}\n",
    "\n",
    "ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ê°€ì´ë“œë¼ì¸:\n",
    "1. ìš”ì²­ê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤ì„ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”\n",
    "2. ê° í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ ì´ìŠˆ í‚¤, í…ŒìŠ¤íŠ¸ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ìŠ¤í…, ì˜ˆìƒ ê²°ê³¼ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”\n",
    "3. ì´ìŠˆë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”\n",
    "4. ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "        )\n",
    "        \n",
    "        query_engine.update_prompts({\"response_synthesizer:text_qa_template\": search_prompt})\n",
    "        \n",
    "        print(\"âœ… ê²€ìƒ‰ìš© ì¿¼ë¦¬ ì—”ì§„ ì„¤ì • ì™„ë£Œ\")\n",
    "        return query_engine\n",
    "    \n",
    "    def _setup_generation_engine(self) -> RetrieverQueryEngine:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ìš© ì¿¼ë¦¬ ì—”ì§„ ì„¤ì •\"\"\"\n",
    "        # ìƒì„±ì— íŠ¹í™”ëœ ë¦¬íŠ¸ë¦¬ë²„ (ì ì€ ìˆ˜ì˜ ê³ í’ˆì§ˆ ì˜ˆì‹œ)\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=self.index,\n",
    "            similarity_top_k=8\n",
    "        )\n",
    "        \n",
    "        # ìƒì„±ìš© í¬ìŠ¤íŠ¸í”„ë¡œì„¸ì„œ (ë†’ì€ í’ˆì§ˆì˜ ì°¸ê³  ìë£Œë§Œ ì„ ë³„)\n",
    "        postprocessors = [\n",
    "            SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "        ]\n",
    "        \n",
    "        query_engine = RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            node_postprocessors=postprocessors\n",
    "        )\n",
    "        \n",
    "        # ìƒì„±ìš© ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸\n",
    "        generation_prompt = PromptTemplate(\n",
    "            \"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤ì˜ íŒ¨í„´ê³¼ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ê³ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³ í•  ê¸°ì¡´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë“¤:\n",
    "{context_str}\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‘ì„± ìš”ì²­: {query_str}\n",
    "\n",
    "ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‘ì„± ê°€ì´ë“œë¼ì¸:\n",
    "1. ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” êµ¬ì²´ì ì¸ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
    "2. í…ŒìŠ¤íŠ¸ ëª©ì , ì „ì œ ì¡°ê±´, í…ŒìŠ¤íŠ¸ ìŠ¤í…, ì˜ˆìƒ ê²°ê³¼ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”\n",
    "3. ê¸°ì¡´ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ íŒ¨í„´ê³¼ í˜•ì‹ì„ ì°¸ê³ í•˜ë˜, ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "4. í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
    "5. Edge Caseë‚˜ ì˜ˆì™¸ ìƒí™©ë„ ê³ ë ¤í•´ì£¼ì„¸ìš”\n",
    "6. ê°€ëŠ¥í•˜ë‹¤ë©´ ì—¬ëŸ¬ ê°œì˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ í˜•ì‹:\n",
    "**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: [í…ŒìŠ¤íŠ¸ ì œëª©]**\n",
    "- **í…ŒìŠ¤íŠ¸ ëª©ì **: [ëª©ì  ì„¤ëª…]\n",
    "- **ì „ì œ ì¡°ê±´**: [ì‚¬ì „ ì¡°ê±´]\n",
    "- **í…ŒìŠ¤íŠ¸ ìŠ¤í…**:\n",
    "  1. [ìŠ¤í… 1]\n",
    "  2. [ìŠ¤í… 2]\n",
    "  ...\n",
    "- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: [í•„ìš”í•œ ë°ì´í„°]\n",
    "- **ì˜ˆìƒ ê²°ê³¼**: [ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼]\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "        )\n",
    "        \n",
    "        query_engine.update_prompts({\"response_synthesizer:text_qa_template\": generation_prompt})\n",
    "        \n",
    "        print(\"âœ… ìƒì„±ìš© ì¿¼ë¦¬ ì—”ì§„ ì„¤ì • ì™„ë£Œ\")\n",
    "        return query_engine\n",
    "    \n",
    "    def find_test_cases(self, query: str, use_advanced_search: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ê¸°ëŠ¥\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ” LlamaIndex ê³ ê¸‰ ê²€ìƒ‰ ì¤‘: {query}\")\n",
    "            \n",
    "            formatted_query = f\"query: {query}\"\n",
    "            \n",
    "            if use_advanced_search:\n",
    "                # ê³ ê¸‰ ê²€ìƒ‰: ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ë° ì¬ë­í‚¹\n",
    "                \n",
    "                # 1ë‹¨ê³„: ë„“ì€ ë²”ìœ„ ê²€ìƒ‰\n",
    "                broad_retriever = VectorIndexRetriever(\n",
    "                    index=self.index,\n",
    "                    similarity_top_k=20\n",
    "                )\n",
    "                broad_nodes = broad_retriever.retrieve(formatted_query)\n",
    "                \n",
    "                # 2ë‹¨ê³„: ê´€ë ¨ì„± ê¸°ë°˜ í•„í„°ë§\n",
    "                similarity_processor = SimilarityPostprocessor(similarity_cutoff=0.5)\n",
    "                filtered_nodes = similarity_processor.postprocess_nodes(broad_nodes)\n",
    "                \n",
    "                # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ì ‘ ì²˜ë¦¬\n",
    "                search_result = self._process_search_nodes(filtered_nodes, query)\n",
    "                \n",
    "                # LLMì„ í†µí•œ ë¶„ì„\n",
    "                analysis_response = self.search_engine.query(formatted_query)\n",
    "                search_result[\"llm_analysis\"] = str(analysis_response)\n",
    "                \n",
    "            else:\n",
    "                # ê¸°ë³¸ ê²€ìƒ‰\n",
    "                response = self.search_engine.query(formatted_query)\n",
    "                search_result = {\n",
    "                    \"query\": query,\n",
    "                    \"llm_analysis\": str(response),\n",
    "                    \"found_nodes\": []\n",
    "                }\n",
    "                \n",
    "                if hasattr(response, 'source_nodes'):\n",
    "                    search_result[\"found_nodes\"] = self._process_search_nodes(response.source_nodes, query)[\"found_nodes\"]\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            self._save_result(\"find_test_cases\", query, search_result)\n",
    "            \n",
    "            return search_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            error_result = {\"query\": query, \"error\": error_msg}\n",
    "            self._save_result(\"find_test_cases\", query, error_result)\n",
    "            return error_result\n",
    "    \n",
    "    def generate_test_case(self, requirement: str, use_advanced_generation: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ê¸°ëŠ¥\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸš€ LlamaIndex ê³ ê¸‰ ìƒì„± ì¤‘: {requirement}\")\n",
    "            \n",
    "            formatted_requirement = f\"query: {requirement}\"\n",
    "            \n",
    "            if use_advanced_generation:\n",
    "                # ê³ ê¸‰ ìƒì„±: ì°¸ì¡° ìë£Œ í’ˆì§ˆ ìµœì í™”\n",
    "                \n",
    "                # 1ë‹¨ê³„: ê´€ë ¨ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰\n",
    "                reference_retriever = VectorIndexRetriever(\n",
    "                    index=self.index,\n",
    "                    similarity_top_k=15\n",
    "                )\n",
    "                reference_nodes = reference_retriever.retrieve(formatted_requirement)\n",
    "                \n",
    "                # 2ë‹¨ê³„: ê³ í’ˆì§ˆ ì°¸ì¡° ìë£Œë§Œ ì„ ë³„\n",
    "                quality_processor = SimilarityPostprocessor(similarity_cutoff=0.8)\n",
    "                quality_nodes = quality_processor.postprocess_nodes(reference_nodes)\n",
    "                \n",
    "                # ì°¸ì¡° ìë£Œ ë¶„ì„\n",
    "                reference_analysis = self._analyze_reference_nodes(quality_nodes)\n",
    "                \n",
    "                # LLMì„ í†µí•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±\n",
    "                generation_response = self.generation_engine.query(formatted_requirement)\n",
    "                \n",
    "                generation_result = {\n",
    "                    \"requirement\": requirement,\n",
    "                    \"generated_test_case\": str(generation_response),\n",
    "                    \"reference_analysis\": reference_analysis,\n",
    "                    \"reference_count\": len(quality_nodes),\n",
    "                    \"generation_quality_score\": self._calculate_generation_quality(str(generation_response))\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "                # ê¸°ë³¸ ìƒì„±\n",
    "                response = self.generation_engine.query(formatted_requirement)\n",
    "                generation_result = {\n",
    "                    \"requirement\": requirement,\n",
    "                    \"generated_test_case\": str(response),\n",
    "                    \"reference_count\": 0\n",
    "                }\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            self._save_result(\"generate_test_case\", requirement, generation_result)\n",
    "            \n",
    "            return generation_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            error_result = {\"requirement\": requirement, \"error\": error_msg}\n",
    "            self._save_result(\"generate_test_case\", requirement, error_result)\n",
    "            return error_result\n",
    "    \n",
    "    def _process_search_nodes(self, nodes, query):\n",
    "        \"\"\"ê²€ìƒ‰ ë…¸ë“œë“¤ì„ ì²˜ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²°ê³¼ ìƒì„±\"\"\"\n",
    "        found_nodes = []\n",
    "        issue_groups = {}\n",
    "        \n",
    "        for node in nodes:\n",
    "            node_info = {\n",
    "                \"content\": node.text,\n",
    "                \"metadata\": node.metadata,\n",
    "                \"score\": float(node.score) if node.score else 0.0,\n",
    "                \"issue_key\": node.metadata.get(\"issue_key\", \"\"),\n",
    "                \"step_index\": node.metadata.get(\"step_index\", \"\")\n",
    "            }\n",
    "            found_nodes.append(node_info)\n",
    "            \n",
    "            # ì´ìŠˆë³„ ê·¸ë£¹í•‘\n",
    "            issue_key = node.metadata.get(\"issue_key\", \"UNKNOWN\")\n",
    "            if issue_key not in issue_groups:\n",
    "                issue_groups[issue_key] = []\n",
    "            issue_groups[issue_key].append(node_info)\n",
    "        \n",
    "        # ì´ìŠˆë³„ ì •ë ¬\n",
    "        for issue_key in issue_groups:\n",
    "            issue_groups[issue_key].sort(\n",
    "                key=lambda x: int(x[\"step_index\"]) if x[\"step_index\"].isdigit() else 0\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"found_nodes\": found_nodes,\n",
    "            \"issue_groups\": issue_groups,\n",
    "            \"total_found\": len(found_nodes),\n",
    "            \"unique_issues\": len(issue_groups)\n",
    "        }\n",
    "    \n",
    "    def _analyze_reference_nodes(self, nodes):\n",
    "        \"\"\"ì°¸ì¡° ë…¸ë“œë“¤ì„ ë¶„ì„í•˜ì—¬ íŒ¨í„´ ì¶”ì¶œ\"\"\"\n",
    "        if not nodes:\n",
    "            return {\"pattern_analysis\": \"ì°¸ì¡° ìë£Œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"}\n",
    "        \n",
    "        patterns = {\n",
    "            \"common_steps\": [],\n",
    "            \"test_data_patterns\": [],\n",
    "            \"result_patterns\": [],\n",
    "            \"issue_types\": set()\n",
    "        }\n",
    "        \n",
    "        for node in nodes:\n",
    "            # ì´ìŠˆ íƒ€ì… ìˆ˜ì§‘\n",
    "            issue_key = node.metadata.get(\"issue_key\", \"\")\n",
    "            if issue_key:\n",
    "                patterns[\"issue_types\"].add(issue_key.split(\"-\")[0] if \"-\" in issue_key else issue_key)\n",
    "            \n",
    "            # í…ìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)\n",
    "            content = node.text.lower()\n",
    "            if \"step\" in content:\n",
    "                patterns[\"common_steps\"].append(content[:100])\n",
    "            if \"data\" in content:\n",
    "                patterns[\"test_data_patterns\"].append(content[:100])\n",
    "            if \"result\" in content or \"expected\" in content:\n",
    "                patterns[\"result_patterns\"].append(content[:100])\n",
    "        \n",
    "        patterns[\"issue_types\"] = list(patterns[\"issue_types\"])\n",
    "        \n",
    "        return {\n",
    "            \"pattern_analysis\": f\"ë¶„ì„ëœ {len(nodes)}ê°œ ì°¸ì¡° ìë£Œì—ì„œ {len(patterns['issue_types'])}ê°œ ì´ìŠˆ íƒ€ì… ë°œê²¬\",\n",
    "            \"patterns\": patterns,\n",
    "            \"reference_quality\": len(nodes)\n",
    "        }\n",
    "    \n",
    "    def _calculate_generation_quality(self, generated_text):\n",
    "        \"\"\"ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)\"\"\"\n",
    "        quality_score = 0\n",
    "        \n",
    "        # ê¸°ë³¸ êµ¬ì¡° í™•ì¸\n",
    "        if \"í…ŒìŠ¤íŠ¸\" in generated_text:\n",
    "            quality_score += 10\n",
    "        if \"ìŠ¤í…\" in generated_text or \"ë‹¨ê³„\" in generated_text:\n",
    "            quality_score += 15\n",
    "        if \"ì˜ˆìƒ\" in generated_text or \"ê²°ê³¼\" in generated_text:\n",
    "            quality_score += 15\n",
    "        if \"ë°ì´í„°\" in generated_text:\n",
    "            quality_score += 10\n",
    "        if \"ì¡°ê±´\" in generated_text:\n",
    "            quality_score += 10\n",
    "        \n",
    "        # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•Šì€ ì ì ˆí•œ ê¸¸ì´)\n",
    "        text_length = len(generated_text)\n",
    "        if 200 <= text_length <= 2000:\n",
    "            quality_score += 20\n",
    "        elif text_length > 100:\n",
    "            quality_score += 10\n",
    "        \n",
    "        # êµ¬ì²´ì„± ì ìˆ˜ (ìˆ«ìë‚˜ êµ¬ì²´ì ì¸ ìš©ì–´ í¬í•¨)\n",
    "        import re\n",
    "        if re.search(r'\\d+', generated_text):\n",
    "            quality_score += 10\n",
    "        if len(re.findall(r'[ê°€-í£]{2,}', generated_text)) > 10:\n",
    "            quality_score += 10\n",
    "        \n",
    "        return min(quality_score, 100)  # ìµœëŒ€ 100ì \n",
    "    \n",
    "    def _save_result(self, test_type: str, query: str, result: Any):\n",
    "        \"\"\"ê²°ê³¼ ì €ì¥\"\"\"\n",
    "        self.test_results.append({\n",
    "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "            \"framework\": \"llamaindex\",\n",
    "            \"test_type\": test_type,\n",
    "            \"query\": query,\n",
    "            \"result\": result\n",
    "        })\n",
    "    \n",
    "    def save_results_to_file(self, filename: str = None):\n",
    "        \"\"\"ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"llamaindex_testcase_results_{timestamp}.json\"\n",
    "        \n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.test_results, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"âœ… LlamaIndex ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    def print_find_result(self, result: Dict[str, Any]):\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        print(f\"\\nğŸ” LlamaIndex ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {result['error']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ“ ê²€ìƒ‰ ì¿¼ë¦¬: {result['query']}\")\n",
    "        \n",
    "        if \"found_nodes\" in result:\n",
    "            print(f\"ğŸ“Š ì°¾ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤: {result.get('total_found', 0)}ê°œ\")\n",
    "            print(f\"ğŸ·ï¸ ê´€ë ¨ ì´ìŠˆ: {result.get('unique_issues', 0)}ê°œ\")\n",
    "        \n",
    "        if \"llm_analysis\" in result:\n",
    "            print(f\"\\nğŸ¤– LLM ë¶„ì„ ê²°ê³¼:\")\n",
    "            print(result['llm_analysis'])\n",
    "        \n",
    "        if \"issue_groups\" in result:\n",
    "            print(f\"\\nğŸ“š ì´ìŠˆë³„ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\")\n",
    "            for issue_key, nodes in list(result['issue_groups'].items())[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥\n",
    "                print(f\"\\nğŸ”— {issue_key}:\")\n",
    "                for i, node in enumerate(nodes[:2], 1):  # ê° ì´ìŠˆë‹¹ 2ê°œê¹Œì§€ë§Œ\n",
    "                    score = node.get('score', 0)\n",
    "                    print(f\"  {i}. (ì ìˆ˜: {score:.3f}) {node['content'][:120]}...\")\n",
    "    \n",
    "    def print_generation_result(self, result: Dict[str, Any]):\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        print(f\"\\nğŸš€ LlamaIndex ìƒì„± ê²°ê³¼:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {result['error']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ“‹ ìš”êµ¬ì‚¬í•­: {result['requirement']}\")\n",
    "        print(f\"ğŸ“Š ì°¸ì¡° ìë£Œ: {result.get('reference_count', 0)}ê°œ\")\n",
    "        \n",
    "        if \"generation_quality_score\" in result:\n",
    "            quality = result['generation_quality_score']\n",
    "            print(f\"â­ ìƒì„± í’ˆì§ˆ ì ìˆ˜: {quality}/100\")\n",
    "        \n",
    "        if \"reference_analysis\" in result:\n",
    "            ref_analysis = result['reference_analysis']\n",
    "            print(f\"ğŸ” ì°¸ì¡° ë¶„ì„: {ref_analysis.get('pattern_analysis', 'N/A')}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result['generated_test_case'])\n",
    "    \n",
    "    def run_comprehensive_test(self):\n",
    "        \"\"\"LlamaIndex ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸš€ LlamaIndex í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì°¾ê¸° í…ŒìŠ¤íŠ¸ë“¤\n",
    "        find_queries = [\n",
    "            \"Master Adminê³¼ ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤‘ì—ì„œ master admin ì„¤ì • ê°¯ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì¤˜\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nğŸ” ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"-\" * 40)\n",
    "        for query in find_queries:\n",
    "            result = self.find_test_cases(query, use_advanced_search=True)\n",
    "            self.print_find_result(result)\n",
    "            print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "        \n",
    "        # 2. ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ë“¤\n",
    "        generation_requirements = [\n",
    "            \"ì¥ì¹˜ì— ì „ì²´ ê´€ë¦¬ì ì„¤ì •ì„ ê°•ì œí•  ìˆ˜ ìˆëŠ” Master Admin ê¸°ëŠ¥ì´ ìˆëŠ”ë° ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘ì„ í•´. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ë™ì‘ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì¡°ê±´ì´ ìˆì–´. ë²„ì „ì´ V1.4.0 ì´ìƒìœ¼ë¡œ ìƒì‚°ëœ ì œí’ˆì´ì–´ì•¼í•´. ì¡°ê±´ì— ë¶€í•©ë˜ëŠ” ì¥ì¹˜ì˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ í™”ë©´ì— Master Admin ì„¤ì •í™”ë©´ì´ í‘œì‹œê°€ ë¼. í•˜ì§€ë§Œ ë²„ì „ì´ V1.4.0 ì´í•˜ë¡œ ìƒì‚°ëœ ì œí’ˆì˜ ê²½ìš°ì—ëŠ” ì¥ì¹˜ ì „ì›ì´ ì¸ê°€ë˜ë©´ ë©”ì¸í™”ë©´ì´ í‘œì‹œê°€ ë¼. ë²„ì „ì€ BS3ì˜ ì´ì „ ë²„ì „ë“¤ì„ ì°¸ê³ í•´ì„œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‘ì„±í•´ì¤˜.\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nğŸš€ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"-\" * 40)\n",
    "        for requirement in generation_requirements:\n",
    "            result = self.generate_test_case(requirement, use_advanced_generation=True)\n",
    "            self.print_generation_result(result)\n",
    "            print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        self.save_results_to_file()\n",
    "        \n",
    "        print(f\"\\nğŸ‰ LlamaIndex ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "        print(f\"ì´ {len(self.test_results)}ê°œì˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # LlamaIndex í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    llamaindex_system = LlamaIndexTestCaseSystem(\n",
    "        lm_studio_url=\"http://127.0.0.1:1234/v1\",\n",
    "        lm_studio_model=\"qwen/qwen3-8b\"\n",
    "    )\n",
    "    \n",
    "    # ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    llamaindex_system.run_comprehensive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMAINDEX WITH LANGCHAIN\n",
    "# Test\n",
    "# Test\n",
    "# Test\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, Document, StorageContext, Settings\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.llms import CustomLLM, CompletionResponse, LLMMetadata\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters, FilterOperator\n",
    "\n",
    "# LangChain ê´€ë ¨ ì„í¬íŠ¸\n",
    "from langchain_community.llms import OpenAI # LM Studioë¥¼ OpenAI API í˜¸í™˜ìœ¼ë¡œ ì‚¬ìš©í•  ê²½ìš°\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate as LCPromptTemplate # LangChainì˜ PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from llama_index.core.langchain_helpers import LlamaIndexRetriever # LlamaIndex ë¦¬íŠ¸ë¦¬ë²„ë¥¼ LangChainì— í†µí•©\n",
    "\n",
    "from typing import List, Dict, Any, Optional, Generator, Sequence\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "# LangChain DeprecationWarning ë¬´ì‹œ (í•´ê²°ë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ë©° ì„ì‹œ ì¡°ì¹˜)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='langchain_core._api.deprecation')\n",
    "\n",
    "\n",
    "class LMStudioLLM(CustomLLM):\n",
    "    \"\"\"LM Studioì™€ ì—°ë™í•˜ëŠ” LlamaIndexìš© ì»¤ìŠ¤í…€ LLM í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    model_name: str = \"qwen/qwen3-8b\"\n",
    "    base_url: str = \"http://127.0.0.1:1234/v1\"\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 2048\n",
    "    \n",
    "    def __init__(self, \n",
    "                 base_url: str = \"http://127.0.0.1:1234/v1\",\n",
    "                 model_name: str = \"qwen/qwen3-8b\",\n",
    "                 temperature: float = 0.1,\n",
    "                 max_tokens: int = 2048,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self._test_connection()\n",
    "    \n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/models\", timeout=100000)\n",
    "            if response.status_code == 200:\n",
    "                models = response.json()\n",
    "                print(f\"âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models.get('data', []))}ê°œ\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ LM Studio ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LM Studio ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "            print(\"LM Studioê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        return LLMMetadata(\n",
    "            context_window=8192,\n",
    "            num_output=self.max_tokens,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "    \n",
    "    def complete(self, prompt: str, **kwargs) -> CompletionResponse:\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"temperature\": self.temperature,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=100000\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return CompletionResponse(text=text)\n",
    "            else:\n",
    "                error_text = f\"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})\"\n",
    "                return CompletionResponse(text=error_text)\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_text = f\"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}\"\n",
    "            return CompletionResponse(text=error_text)\n",
    "    \n",
    "    def chat(self, messages: Sequence[ChatMessage], **kwargs) -> CompletionResponse:\n",
    "        formatted_messages = []\n",
    "        for msg in messages:\n",
    "            formatted_messages.append({\n",
    "                \"role\": msg.role.value if hasattr(msg.role, 'value') else str(msg.role),\n",
    "                \"content\": msg.content\n",
    "            })\n",
    "        \n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": formatted_messages,\n",
    "                \"temperature\": self.temperature,\n",
    "                \"max_tokens\": self.max_tokens,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return CompletionResponse(text=text)\n",
    "            else:\n",
    "                error_text = f\"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})\"\n",
    "                return CompletionResponse(text=error_text)\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_text = f\"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}\"\n",
    "            return CompletionResponse(text=error_text)\n",
    "    \n",
    "    def stream_complete(self, prompt: str, **kwargs) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.complete(prompt, **kwargs)\n",
    "        yield response\n",
    "    \n",
    "    def stream_chat(self, messages: Sequence[ChatMessage], **kwargs) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.chat(messages, **kwargs)\n",
    "        yield response\n",
    "\n",
    "\n",
    "class TestCaseRAGLlamaIndexLMStudio:\n",
    "    def __init__(self, \n",
    "                 persist_directory: str = \"./chroma_db\",\n",
    "                 collection_name: str = \"jira_test_cases\",\n",
    "                 embedding_model_name: str = \"intfloat/multilingual-e5-large\",\n",
    "                 lm_studio_url: str = \"http://localhost:1234/v1\",\n",
    "                 lm_studio_model: str = \"local-model\"):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = collection_name\n",
    "        self.lm_studio_url = lm_studio_url\n",
    "        self.lm_studio_model = lm_studio_model\n",
    "        \n",
    "        self._setup_global_settings(embedding_model_name)\n",
    "        self.vector_store = self._connect_to_chroma()\n",
    "        self.index = self._create_index()\n",
    "        self.query_engine = self._setup_query_engine()\n",
    "        self._setup_custom_prompts()\n",
    "    \n",
    "    def _setup_global_settings(self, embedding_model_name: str):\n",
    "        Settings.embed_model = HuggingFaceEmbedding(\n",
    "            model_name=embedding_model_name,\n",
    "            device=\"cpu\",\n",
    "            trust_remote_code=True,\n",
    "            normalize=True,\n",
    "            query_instruction=\"query:\",  \n",
    "            text_instruction=\"passage:\", \n",
    "        )\n",
    "        \n",
    "        Settings.llm = LMStudioLLM(\n",
    "            base_url=self.lm_studio_url,\n",
    "            model_name=self.lm_studio_model,\n",
    "            temperature=0.1,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        print(f\"âœ… LM Studio LLM ì„¤ì • ì™„ë£Œ: {self.lm_studio_url}\")\n",
    "    \n",
    "    def _connect_to_chroma(self) -> ChromaVectorStore:\n",
    "        try:\n",
    "            chroma_client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            chroma_collection = chroma_client.get_or_create_collection(name=self.collection_name)\n",
    "            vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "            print(f\"âœ… ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ '{self.collection_name}' ì—°ê²° ì™„ë£Œ\")\n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_index(self) -> VectorStoreIndex:\n",
    "        try:\n",
    "            storage_context = StorageContext.from_defaults(vector_store=self.vector_store)\n",
    "            index = VectorStoreIndex.from_vector_store(\n",
    "                vector_store=self.vector_store,\n",
    "                storage_context=storage_context\n",
    "            )\n",
    "            print(\"âœ… LlamaIndex ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "            return index\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _setup_query_engine(self) -> RetrieverQueryEngine:\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=self.index,\n",
    "            similarity_top_k=8,\n",
    "            vector_store_query_mode=\"default\"\n",
    "        )\n",
    "        postprocessors = [\n",
    "            SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "        ]\n",
    "        query_engine = RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            node_postprocessors=postprocessors\n",
    "        )\n",
    "        print(\"âœ… LM Studio ì¿¼ë¦¬ ì—”ì§„ ì„¤ì • ì™„ë£Œ\")\n",
    "        return query_engine\n",
    "    \n",
    "    def _setup_custom_prompts(self):\n",
    "        qa_prompt_template = PromptTemplate(\n",
    "            \"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³ í•  í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤:\n",
    "{context_str}\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {query_str}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
    "2. ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ì˜ ëª©ì ê³¼ ì˜ˆìƒ ê²°ê³¼ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”\n",
    "3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”\n",
    "4. ì´ìŠˆ í‚¤ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ì „ì²´ì ì¸ í…ŒìŠ¤íŠ¸ íë¦„ì„ ë³´ì—¬ì£¼ì„¸ìš”\n",
    "5. ì°¾ì€ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "6. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "        )\n",
    "        self.query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_template})\n",
    "    \n",
    "    def search_test_cases(self, \n",
    "                         query: str, \n",
    "                         filters: Optional[Dict[str, Any]] = None,\n",
    "                         top_k: int = 10) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            formatted_query = query \n",
    "            llama_filters = None\n",
    "            if filters:\n",
    "                llama_filters = MetadataFilters(\n",
    "                    filters=[ExactMatchFilter(key=k, value=v) for k, v in filters.items()],\n",
    "                    condition=FilterOperator.AND\n",
    "                )\n",
    "\n",
    "            retriever = VectorIndexRetriever(\n",
    "                index=self.index,\n",
    "                similarity_top_k=top_k,\n",
    "                filters=llama_filters\n",
    "            )\n",
    "            \n",
    "            nodes = retriever.retrieve(formatted_query)\n",
    "            \n",
    "            results = []\n",
    "            for node in nodes:\n",
    "                result = {\n",
    "                    \"content\": node.text,\n",
    "                    \"metadata\": node.metadata,\n",
    "                    \"similarity_score\": float(node.score) if node.score else 0.0,\n",
    "                    \"node_id\": node.node_id\n",
    "                }\n",
    "                results.append(result)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def ask_question(self, question: str, filters: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "        try:\n",
    "            print(f\"ğŸ¤– LM Studioë¡œ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {question}\")\n",
    "            formatted_question = question\n",
    "            current_query_engine = self.query_engine\n",
    "            \n",
    "            if filters:\n",
    "                llama_filters = MetadataFilters(\n",
    "                    filters=[ExactMatchFilter(key=k, value=v) for k, v in filters.items()],\n",
    "                    condition=FilterOperator.AND\n",
    "                )\n",
    "\n",
    "                retriever = VectorIndexRetriever(\n",
    "                    index=self.index,\n",
    "                    similarity_top_k=8,\n",
    "                    filters=llama_filters\n",
    "                )\n",
    "                postprocessors = [SimilarityPostprocessor(similarity_cutoff=0.7)]\n",
    "                query_engine = RetrieverQueryEngine(\n",
    "                    retriever=retriever,\n",
    "                    node_postprocessors=postprocessors\n",
    "                )\n",
    "                qa_prompt_template = PromptTemplate(\n",
    "                    \"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³ í•  í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤:\n",
    "{context_str}\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {query_str}\n",
    "\n",
    "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "                )\n",
    "                query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_template})\n",
    "                current_query_engine = query_engine\n",
    "            \n",
    "            response = current_query_engine.query(formatted_question)\n",
    "            \n",
    "            source_nodes = []\n",
    "            if hasattr(response, 'source_nodes'):\n",
    "                for node in response.source_nodes:\n",
    "                    source_nodes.append({\n",
    "                        \"content\": node.text,\n",
    "                        \"metadata\": node.metadata,\n",
    "                        \"score\": float(node.score) if node.score else 0.0\n",
    "                    })\n",
    "            \n",
    "            grouped_sources = self.group_results_by_issue(source_nodes)\n",
    "            \n",
    "            return {\n",
    "                \"answer\": str(response),\n",
    "                \"source_nodes\": source_nodes,\n",
    "                \"grouped_sources\": grouped_sources,\n",
    "                \"response_metadata\": response.metadata if hasattr(response, 'metadata') else {}\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return {\n",
    "                \"answer\": \"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\",\n",
    "                \"source_nodes\": [],\n",
    "                \"grouped_sources\": {},\n",
    "                \"response_metadata\": {}\n",
    "            }\n",
    "    \n",
    "    def group_results_by_issue(self, results: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        grouped = {}\n",
    "        for result in results:\n",
    "            issue_key = result[\"metadata\"].get(\"issue_key\", \"UNKNOWN\")\n",
    "            if issue_key not in grouped:\n",
    "                grouped[issue_key] = []\n",
    "            grouped[issue_key].append(result)\n",
    "        \n",
    "        for issue_key in grouped:\n",
    "            grouped[issue_key].sort(\n",
    "                key=lambda x: int(x[\"metadata\"].get(\"step_index\", \"0\"))\n",
    "            )\n",
    "        return grouped\n",
    "    \n",
    "    def get_test_case_by_issue(self, issue_key: str) -> List[Dict[str, Any]]:\n",
    "        filters = {\"issue_key\": issue_key}\n",
    "        results = self.search_test_cases(\"\", filters=filters, top_k=50) \n",
    "        results.sort(key=lambda x: int(x[\"metadata\"].get(\"step_index\", \"0\")))\n",
    "        return results\n",
    "    \n",
    "    def create_custom_query_engine(self, \n",
    "                                  similarity_top_k: int = 8,\n",
    "                                  similarity_cutoff: float = 0.7,\n",
    "                                  filters: Optional[Dict[str, Any]] = None) -> RetrieverQueryEngine:\n",
    "        llama_filters = None\n",
    "        if filters:\n",
    "            llama_filters = MetadataFilters(\n",
    "                filters=[ExactMatchFilter(key=k, value=v) for k, v in filters.items()],\n",
    "                condition=FilterOperator.AND\n",
    "            )\n",
    "\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=self.index,\n",
    "            similarity_top_k=similarity_top_k,\n",
    "            filters=llama_filters\n",
    "        )\n",
    "        \n",
    "        postprocessors = [SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)]\n",
    "        \n",
    "        query_engine = RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            node_postprocessors=postprocessors\n",
    "        )\n",
    "        \n",
    "        qa_prompt_template = PromptTemplate(\n",
    "            \"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³ í•  í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤:\n",
    "{context_str}\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {query_str}\n",
    "\n",
    "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "        )\n",
    "        query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_template})\n",
    "        return query_engine\n",
    "    \n",
    "    def test_lm_studio_direct(self, prompt: str) -> str:\n",
    "        response = Settings.llm.complete(prompt)\n",
    "        return response.text\n",
    "    \n",
    "    def print_search_results(self, results: List[Dict[str, Any]]):\n",
    "        if not results:\n",
    "            print(\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        grouped = self.group_results_by_issue(results)\n",
    "        \n",
    "        for issue_key, steps in grouped.items():\n",
    "            print(f\"\\nğŸ” ì´ìŠˆ: {issue_key}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            for step in steps:\n",
    "                step_idx = step[\"metadata\"].get(\"step_index\", \"N/A\")\n",
    "                score = step.get(\"similarity_score\", 0)\n",
    "                print(f\"\\nğŸ“‹ Step {step_idx} (ìœ ì‚¬ë„: {score:.3f})\")\n",
    "                print(\"-\" * 30)\n",
    "                print(step[\"content\"])\n",
    "    \n",
    "    def print_qa_result(self, result: Dict[str, Any]):\n",
    "        print(f\"\\nğŸ’¡ LM Studio ë‹µë³€:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(result[\"answer\"])\n",
    "        \n",
    "        if result[\"grouped_sources\"]:\n",
    "            print(f\"\\nğŸ“š ì°¸ê³ í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤:\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            for issue_key, steps in result[\"grouped_sources\"].items():\n",
    "                print(f\"\\nğŸ”— {issue_key}\")\n",
    "                for step in steps:\n",
    "                    step_idx = step[\"metadata\"].get(\"step_index\", \"N/A\")\n",
    "                    score = step.get(\"score\", 0)\n",
    "                    print(f\"  Step {step_idx} (ì ìˆ˜: {score:.3f}): {step['content'][:100]}...\")\n",
    "\n",
    "    def save_json_to_file(self, filename: str, data: Dict[str, Any]):\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"âœ… ëª¨ë“  ê²°ê³¼ê°€ '{filename}' íŒŒì¼ì— JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except IOError as e:\n",
    "            print(f\"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    rag = TestCaseRAGLlamaIndexLMStudio(\n",
    "        lm_studio_url=\"http://127.0.0.1:1234/v1\",\n",
    "        lm_studio_model=\"qwen/qwen3-8b\"\n",
    "    )\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # LangChain ì—°ë™ ì˜ˆì‹œ\n",
    "    # ---------------------------------------------\n",
    "    print(\"\\n--- LangChain ì—°ë™ í…ŒìŠ¤íŠ¸ ---\")\n",
    "\n",
    "    # LM Studioë¥¼ LangChainì˜ LLMìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ OpenAIWrapper ì„¤ì •\n",
    "    # LM StudioëŠ” OpenAI APIì™€ í˜¸í™˜ë˜ë¯€ë¡œ langchain_community.llms.OpenAI ì‚¬ìš©\n",
    "    lc_llm = OpenAI(\n",
    "        base_url=rag.lm_studio_url,\n",
    "        model_name=rag.lm_studio_model,\n",
    "        temperature=rag.temperature,\n",
    "        max_tokens=rag.max_tokens\n",
    "    )\n",
    "    print(f\"âœ… LangChainìš© LM Studio LLM ì„¤ì • ì™„ë£Œ: {rag.lm_studio_url}\")\n",
    "\n",
    "    # LlamaIndexì˜ Retrieverë¥¼ LangChainì˜ Retrieverë¡œ ë³€í™˜\n",
    "    # LlamaIndexì˜ ê¸°ë³¸ Retriever ì„¤ì • (í•„í„°ë§ ì—†ì´)\n",
    "    llama_index_base_retriever = VectorIndexRetriever(\n",
    "        index=rag.index,\n",
    "        similarity_top_k=8,\n",
    "        vector_store_query_mode=\"default\"\n",
    "    )\n",
    "    # LlamaIndex Retrieverë¥¼ LangChain Retrieverë¡œ ë˜í•‘\n",
    "    lc_retriever = LlamaIndexRetriever(llama_index_base_retriever)\n",
    "    print(\"âœ… LlamaIndex Retrieverë¥¼ LangChain í˜¸í™˜ Retrieverë¡œ ë³€í™˜ ì™„ë£Œ\")\n",
    "\n",
    "    # LangChain RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "    # (LlamaIndex í”„ë¡¬í”„íŠ¸ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ LangChain PromptTemplate ì‚¬ìš©)\n",
    "    lc_template = \"\"\"ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ê³ í•  í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤:\n",
    "{context}\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ê´€ë ¨ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í…ë“¤ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
    "2. ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ì˜ ëª©ì ê³¼ ì˜ˆìƒ ê²°ê³¼ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”\n",
    "3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”\n",
    "4. ì´ìŠˆ í‚¤ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ì „ì²´ì ì¸ í…ŒìŠ¤íŠ¸ íë¦„ì„ ë³´ì—¬ì£¼ì„¸ìš”\n",
    "5. ì°¾ì€ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
    "6. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "    lc_prompt = LCPromptTemplate.from_template(lc_template)\n",
    "\n",
    "    # LangChain RAG ì²´ì¸ êµ¬ì¶• (LCEL: LangChain Expression Language)\n",
    "    # RAG ì²´ì¸ì€ retrieverë¡œ ë¬¸ì„œë¥¼ ì°¾ê³ , ì´ ë¬¸ì„œë¥¼ contextë¡œ ì‚¬ìš©í•˜ì—¬ LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    lc_rag_chain = (\n",
    "        {\"context\": lc_retriever, \"question\": RunnablePassthrough()}\n",
    "        | lc_prompt\n",
    "        | lc_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    print(\"âœ… LangChain RAG ì²´ì¸ êµ¬ì¶• ì™„ë£Œ\")\n",
    "\n",
    "    # LangChain RAG ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸í•˜ê¸°\n",
    "    langchain_question = \"master admin í…ŒìŠ¤íŠ¸ì˜ ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "    print(f\"\\nğŸ’¬ LangChain RAG ì²´ì¸ìœ¼ë¡œ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {langchain_question}\")\n",
    "    langchain_answer = lc_rag_chain.invoke(langchain_question)\n",
    "    print(f\"\\nğŸ’¡ LangChain RAG ë‹µë³€:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(langchain_answer)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì½”ë“œ (JSON ì €ì¥ì„ ìœ„í•´ all_test_resultsì— ì¶”ê°€)\n",
    "    # ---------------------------------------------\n",
    "    all_test_results = {}\n",
    "\n",
    "    print(\"ğŸ¤– LM Studio ì§ì ‘ í…ŒìŠ¤íŠ¸\")\n",
    "    direct_response = rag.test_lm_studio_direct(\"ì•ˆë…•í•˜ì„¸ìš”! í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤.\")\n",
    "    print(f\"ì‘ë‹µ: {direct_response}\")\n",
    "    all_test_results[\"direct_lm_studio_test\"] = {\"query\": \"ì•ˆë…•í•˜ì„¸ìš”! í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤.\", \"response\": direct_response}\n",
    "    \n",
    "    print(\"\\nğŸ” ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "    search_query_1 = \"master admin í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\"\n",
    "    search_results_1 = rag.search_test_cases(search_query_1, top_k=5)\n",
    "    rag.print_search_results(search_results_1)\n",
    "    all_test_results[\"basic_search_test\"] = {\"query\": search_query_1, \"results\": search_results_1}\n",
    "    \n",
    "    print(\"\\nğŸ” í•„í„°ë§ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "    search_query_2 = \"í…ŒìŠ¤íŠ¸\"\n",
    "    filters_2 = {\"issue_key\": \"COMMONR-380\"}\n",
    "    filtered_results_2 = rag.search_test_cases(search_query_2, filters=filters_2, top_k=5)\n",
    "    rag.print_search_results(filtered_results_2)\n",
    "    all_test_results[\"filtered_search_test\"] = {\"query\": search_query_2, \"filters\": filters_2, \"results\": filtered_results_2}\n",
    "    \n",
    "    print(\"\\nğŸ’¬ LM Studio ì§ˆë¬¸ ë‹µë³€ í…ŒìŠ¤íŠ¸\")\n",
    "    qa_question_1 = \"master admin í…ŒìŠ¤íŠ¸ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    qa_result_1 = rag.ask_question(qa_question_1)\n",
    "    rag.print_qa_result(qa_result_1)\n",
    "    all_test_results[\"qa_test_1\"] = {\"question\": qa_question_1, \"response\": qa_result_1}\n",
    "    \n",
    "    print(\"\\nğŸ”§ ì»¤ìŠ¤í…€ ì¿¼ë¦¬ ì—”ì§„ í…ŒìŠ¤íŠ¸\")\n",
    "    custom_engine_query = \"master-slave master admin í…ŒìŠ¤íŠ¸ ë°©ë²•\"\n",
    "    custom_engine_filters = {\"issue_key\": \"COMMONR-380\"} \n",
    "    custom_engine = rag.create_custom_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        similarity_cutoff=0.8,\n",
    "        filters=custom_engine_filters \n",
    "    )\n",
    "    custom_response_obj = custom_engine.query(custom_engine_query)\n",
    "    custom_response_text = str(custom_response_obj)\n",
    "    print(f\"ì»¤ìŠ¤í…€ ë‹µë³€: {custom_response_text}\")\n",
    "\n",
    "    # custom_engineì˜ source_nodesë„ ì €ì¥í•˜ë ¤ë©´, ask_questionì²˜ëŸ¼ ë‚´ë¶€ ë¡œì§ì„ ìˆ˜ì •í•˜ì—¬\n",
    "    # source_nodesë¥¼ ë°˜í™˜í•˜ë„ë¡ í•˜ê±°ë‚˜, query_engineì˜ response ê°ì²´ì—ì„œ ì§ì ‘ ì ‘ê·¼í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìµœì¢… í…ìŠ¤íŠ¸ë§Œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    all_test_results[\"custom_query_engine_test\"] = {\n",
    "        \"query\": custom_engine_query, \n",
    "        \"filters\": custom_engine_filters,\n",
    "        \"answer_text\": custom_response_text,\n",
    "    }\n",
    "    \n",
    "    print(\"\\nğŸ’¬ ë³µì¡í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\")\n",
    "    qa_question_2 = \"master admin í…ŒìŠ¤íŠ¸ì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì ê³¼ í•„ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "    complex_qa_result = rag.ask_question(qa_question_2)\n",
    "    rag.print_qa_result(complex_qa_result)\n",
    "    all_test_results[\"complex_qa_test\"] = {\"question\": qa_question_2, \"response\": complex_qa_result}\n",
    "    \n",
    "    print(\"\\nğŸ“‹ íŠ¹ì • ì´ìŠˆ ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤í… ì¡°íšŒ\")\n",
    "    issue_key_to_retrieve = \"COMMONR-380\"\n",
    "    issue_steps = rag.get_test_case_by_issue(issue_key_to_retrieve)\n",
    "    rag.print_search_results(issue_steps)\n",
    "    all_test_results[\"get_all_steps_by_issue\"] = {\"issue_key\": issue_key_to_retrieve, \"steps\": issue_steps}\n",
    "\n",
    "    # LangChain ê²°ê³¼ë„ JSONì— ì¶”ê°€\n",
    "    all_test_results[\"langchain_rag_test\"] = {\n",
    "        \"question\": langchain_question,\n",
    "        \"answer\": langchain_answer\n",
    "    }\n",
    "\n",
    "    output_filename = \"rag_full_results.json\"\n",
    "    rag.save_json_to_file(output_filename, all_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Jira to ì„ë² ë”© í˜•ì‹ ë³€í™˜ ===\n",
      "Jira URL: https://jira.suprema.co.kr\n",
      "ì‚¬ìš©ì: dhwoo\n",
      "JQL ì¿¼ë¦¬: project = \"COMMONR\" AND issuetype = \"Test\"\n",
      "\n",
      "JQLë¡œ ì´ìŠˆ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤: project = \"COMMONR\" AND issuetype = \"Test\"\n",
      "  -> í˜„ì¬ê¹Œì§€ 100 / 186 ê°œ ì´ìŠˆ í‚¤ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤...\n",
      "  -> í˜„ì¬ê¹Œì§€ 186 / 186 ê°œ ì´ìŠˆ í‚¤ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤...\n",
      "ì´ 186ê°œì˜ ì´ìŠˆë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ìŠˆ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  ì„ë² ë”© í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...\n",
      "[1/186] COMMONR-380 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-380 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[2/186] COMMONR-379 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-379 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[3/186] COMMONR-378 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-378 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[4/186] COMMONR-377 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-377 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[5/186] COMMONR-376 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-376 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[6/186] COMMONR-375 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-375 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[7/186] COMMONR-374 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-374 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[8/186] COMMONR-373 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-373 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[9/186] COMMONR-372 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-372 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[10/186] COMMONR-371 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-371 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[11/186] COMMONR-370 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-370 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[12/186] COMMONR-369 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-369 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[13/186] COMMONR-368 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-368 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[14/186] COMMONR-367 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-367 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[15/186] COMMONR-366 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-366 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[16/186] COMMONR-365 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-365 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[17/186] COMMONR-363 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-363 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[18/186] COMMONR-362 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-362 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[19/186] COMMONR-361 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-361 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[20/186] COMMONR-360 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-360 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[21/186] COMMONR-359 ì²˜ë¦¬ ì¤‘...\n",
      "[22/186] COMMONR-356 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-356 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[23/186] COMMONR-355 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-355 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[24/186] COMMONR-354 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-354 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[25/186] COMMONR-353 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-353 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[26/186] COMMONR-352 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-352 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[27/186] COMMONR-351 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-351 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[28/186] COMMONR-350 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-350 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[29/186] COMMONR-330 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-330 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[30/186] COMMONR-329 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-329 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[31/186] COMMONR-328 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-328 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[32/186] COMMONR-327 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-327 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[33/186] COMMONR-326 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-326 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[34/186] COMMONR-325 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-325 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[35/186] COMMONR-324 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-324 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[36/186] COMMONR-322 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-322 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[37/186] COMMONR-321 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-321 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[38/186] COMMONR-306 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-306 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[39/186] COMMONR-305 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-305 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[40/186] COMMONR-304 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-304 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[41/186] COMMONR-303 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-303 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[42/186] COMMONR-302 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-302 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[43/186] COMMONR-299 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-299 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[44/186] COMMONR-298 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-298 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[45/186] COMMONR-297 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-297 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[46/186] COMMONR-296 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-296 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[47/186] COMMONR-295 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-295 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[48/186] COMMONR-294 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-294 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[49/186] COMMONR-293 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-293 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[50/186] COMMONR-292 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-292 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[51/186] COMMONR-291 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-291 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[52/186] COMMONR-290 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-290 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[53/186] COMMONR-289 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-289 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[54/186] COMMONR-288 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-288 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[55/186] COMMONR-287 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-287 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[56/186] COMMONR-286 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-286 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[57/186] COMMONR-285 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-285 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[58/186] COMMONR-284 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-284 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[59/186] COMMONR-283 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-283 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[60/186] COMMONR-280 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-280 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[61/186] COMMONR-279 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-279 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[62/186] COMMONR-278 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-278 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[63/186] COMMONR-277 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-277 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[64/186] COMMONR-276 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-276 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[65/186] COMMONR-274 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-274 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[66/186] COMMONR-272 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-272 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[67/186] COMMONR-271 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-271 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[68/186] COMMONR-270 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-270 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[69/186] COMMONR-269 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-269 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[70/186] COMMONR-268 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-268 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[71/186] COMMONR-267 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-267 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[72/186] COMMONR-265 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-265 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[73/186] COMMONR-264 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-264 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[74/186] COMMONR-263 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-263 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[75/186] COMMONR-262 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-262 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[76/186] COMMONR-261 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-261 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[77/186] COMMONR-260 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-260 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[78/186] COMMONR-259 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-259 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[79/186] COMMONR-258 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-258 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[80/186] COMMONR-256 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-256 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[81/186] COMMONR-255 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-255 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[82/186] COMMONR-254 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-254 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[83/186] COMMONR-253 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-253 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[84/186] COMMONR-252 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-252 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[85/186] COMMONR-251 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-251 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[86/186] COMMONR-250 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-250 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[87/186] COMMONR-249 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-249 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[88/186] COMMONR-248 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-248 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[89/186] COMMONR-247 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-247 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[90/186] COMMONR-245 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-245 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[91/186] COMMONR-244 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-244 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[92/186] COMMONR-243 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-243 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[93/186] COMMONR-242 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-242 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[94/186] COMMONR-241 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-241 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[95/186] COMMONR-240 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-240 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[96/186] COMMONR-239 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-239 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[97/186] COMMONR-238 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-238 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[98/186] COMMONR-237 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-237 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[99/186] COMMONR-235 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-235 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[100/186] COMMONR-234 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-234 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[101/186] COMMONR-231 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-231 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[102/186] COMMONR-226 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-226 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[103/186] COMMONR-224 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-224 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[104/186] COMMONR-221 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-221 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[105/186] COMMONR-220 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-220 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[106/186] COMMONR-218 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-218 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[107/186] COMMONR-217 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-217 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[108/186] COMMONR-216 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-216 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[109/186] COMMONR-211 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-211 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[110/186] COMMONR-210 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-210 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[111/186] COMMONR-209 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-209 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[112/186] COMMONR-208 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-208 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[113/186] COMMONR-207 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-207 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[114/186] COMMONR-200 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-200 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[115/186] COMMONR-199 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-199 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[116/186] COMMONR-198 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-198 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[117/186] COMMONR-195 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-195 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[118/186] COMMONR-193 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-193 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[119/186] COMMONR-192 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-192 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[120/186] COMMONR-179 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-179 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[121/186] COMMONR-178 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-178 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[122/186] COMMONR-177 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-177 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[123/186] COMMONR-176 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-176 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[124/186] COMMONR-167 ì²˜ë¦¬ ì¤‘...\n",
      "[125/186] COMMONR-156 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-156 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[126/186] COMMONR-151 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-151 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[127/186] COMMONR-149 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-149 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[128/186] COMMONR-148 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-148 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[129/186] COMMONR-126 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-126 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[130/186] COMMONR-124 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-124 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[131/186] COMMONR-123 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-123 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[132/186] COMMONR-107 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-107 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[133/186] COMMONR-106 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-106 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[134/186] COMMONR-104 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-104 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[135/186] COMMONR-103 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-103 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[136/186] COMMONR-101 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-101 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[137/186] COMMONR-100 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-100 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[138/186] COMMONR-99 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-99 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[139/186] COMMONR-95 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-95 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[140/186] COMMONR-93 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-93 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[141/186] COMMONR-82 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-82 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[142/186] COMMONR-79 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-79 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[143/186] COMMONR-78 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-78 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[144/186] COMMONR-77 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-77 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[145/186] COMMONR-76 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-76 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[146/186] COMMONR-75 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-75 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[147/186] COMMONR-74 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-74 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[148/186] COMMONR-72 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-72 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[149/186] COMMONR-71 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-71 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[150/186] COMMONR-70 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-70 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[151/186] COMMONR-69 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-69 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[152/186] COMMONR-68 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-68 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[153/186] COMMONR-62 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-62 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[154/186] COMMONR-60 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-60 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[155/186] COMMONR-58 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-58 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[156/186] COMMONR-57 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-57 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[157/186] COMMONR-56 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-56 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[158/186] COMMONR-55 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-55 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[159/186] COMMONR-54 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-54 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[160/186] COMMONR-44 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-44 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[161/186] COMMONR-42 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-42 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[162/186] COMMONR-41 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-41 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[163/186] COMMONR-40 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-40 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[164/186] COMMONR-39 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-39 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[165/186] COMMONR-38 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-38 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[166/186] COMMONR-36 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-36 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[167/186] COMMONR-35 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-35 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[168/186] COMMONR-34 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-34 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[169/186] COMMONR-32 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-32 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[170/186] COMMONR-31 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-31 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[171/186] COMMONR-30 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-30 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[172/186] COMMONR-29 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-29 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[173/186] COMMONR-24 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-24 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[174/186] COMMONR-23 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-23 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[175/186] COMMONR-22 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-22 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[176/186] COMMONR-21 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-21 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[177/186] COMMONR-20 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-20 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[178/186] COMMONR-19 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-19 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[179/186] COMMONR-15 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-15 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[180/186] COMMONR-13 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-13 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[181/186] COMMONR-12 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-12 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[182/186] COMMONR-11 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-11 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[183/186] COMMONR-9 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-9 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[184/186] COMMONR-8 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-8 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[185/186] COMMONR-4 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-4 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "[186/186] COMMONR-3 ì²˜ë¦¬ ì¤‘...\n",
      " COMMONR-3 ì´ìŠˆì˜ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ í´ë”: 'c:\\Users\\dhwoo\\Desktop\\project\\RAG\\jira_issues_output'\n",
      "\n",
      "ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ìŠˆ: 184/186\n",
      "\n",
      "=== ì„ë² ë”© ë°ì´í„° ìƒ˜í”Œ ===\n",
      "ìƒ˜í”Œ 1:\n",
      "ID: COMMONR-380_step_1\n",
      "Document: Test Step: 1. Device> ê´€ë¦¬ì ì„¤ì •\n",
      "Test Data: 1. Master Password ì„¤ì •\n",
      "2. ì „ì²´ ê´€ë¦¬ì ì„¤ì •\n",
      "3. ì¥ì¹˜ ì„¤ì • ê´€ë¦¬ì ì„¤ì •\n",
      "4. ì‚¬ìš©ì ê´€ë¦¬...\n",
      "Metadata: {'issue_key': 'COMMONR-380', 'step_index': '1', 'source': 'jira_test_step'}\n",
      "--------------------------------------------------\n",
      "ìƒ˜í”Œ 2:\n",
      "ID: COMMONR-380_step_2\n",
      "Document: Test Step: [ì „ì²´ ê´€ë¦¬ì ë¯¸ì„¤ì • ìƒíƒœ]\n",
      "1. ì¥ì¹˜ ë‚´ì—ì„œ ì‚¬ìš©ìì— ì‚¬ìš©ìê´€ë¦¬ì & ì„¤ì • ê´€ë¦¬ì ì„¤ì •\n",
      "2. BioStar Xì—ì„œ ì¥ì¹˜>ê³ ê¸‰ì—ì„œ ì‚¬ìš©ìê´€ë¦¬ì & ì„¤ì • ê´€ë¦¬ì ...\n",
      "Metadata: {'issue_key': 'COMMONR-380', 'step_index': '2', 'source': 'jira_test_step'}\n",
      "--------------------------------------------------\n",
      "ìƒ˜í”Œ 3:\n",
      "ID: COMMONR-380_step_3\n",
      "Document: Test Step: 1. Device> ì „ì²´ê´€ë¦¬ì ì„¤ì •\n",
      "2. ì‚¬ìš©ì ê´€ë¦¬ì & ì„¤ì •ê´€ë¦¬ì ì„¤ì •\n",
      "3. ì„¤ì •í•œ ê´€ë¦¬ìë¡œ ì¶œì…ë¬¸ ì œì–´ ì§„ì… ì‹œë„\n",
      "Expected Result: 1. ì¸ì¦...\n",
      "Metadata: {'issue_key': 'COMMONR-380', 'step_index': '3', 'source': 'jira_test_step'}\n",
      "--------------------------------------------------\n",
      "\n",
      "=== í†µê³„ ===\n",
      "ì´ 2632ê°œì˜ ì„ë² ë”© ê°ì²´ ìƒì„±\n",
      "ì´ìŠˆë‹¹ í‰ê·  14.2ê°œì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í…\n",
      "í‰ê·  ë¬¸ì„œ ê¸¸ì´: 310 ë¬¸ì\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"=== Jira to ì„ë² ë”© í˜•ì‹ ë³€í™˜ ===\")\n",
    "    print(f\"Jira URL: {JIRA_URL}\")\n",
    "    print(f\"ì‚¬ìš©ì: {JIRA_USERNAME}\")\n",
    "    print(f\"JQL ì¿¼ë¦¬: {JQL_QUERY}\")\n",
    "    print()\n",
    "\n",
    "    # 1. ì´ìŠˆ í‚¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "    issue_keys = get_all_jira_issue_keys(JQL_QUERY)\n",
    "    \n",
    "    if not issue_keys:\n",
    "        print(\"ê²€ìƒ‰ëœ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ì´ {len(issue_keys)}ê°œì˜ ì´ìŠˆë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print()\n",
    "    \n",
    "    # 2. ëª¨ë“  ì´ìŠˆ ë°ì´í„°ë¥¼ ì„ë² ë”© í˜•íƒœë¡œ ë³€í™˜\n",
    "    all_embedding_data = []\n",
    "    successful_count = 0\n",
    "    \n",
    "    print(\"ì´ìŠˆ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  ì„ë² ë”© í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...\")\n",
    "    \n",
    "    for i, issue_key in enumerate(issue_keys, 1):\n",
    "        print(f\"[{i}/{len(issue_keys)}] {issue_key} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì„ë² ë”©ìš© í˜•íƒœë¡œ ë³€í™˜\n",
    "        embedding_objects = convert_to_embedding_format(issue_key)\n",
    "        if embedding_objects:\n",
    "            all_embedding_data.extend(embedding_objects)  # ë¦¬ìŠ¤íŠ¸ í™•ì¥\n",
    "            # ê°œë³„ ì´ìŠˆë³„ë¡œ JSON íŒŒì¼ ì €ì¥\n",
    "            json_to_save_file(embedding_objects, issue_key)\n",
    "            successful_count += 1\n",
    "        \n",
    "        # API í˜¸ì¶œ ì œí•œ ê³ ë ¤\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"\\nì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ìŠˆ: {successful_count}/{len(issue_keys)}\")\n",
    "    \n",
    "    # 3. ì„ë² ë”© ë°ì´í„° ì¶œë ¥ (ì²˜ìŒ 3ê°œë§Œ ìƒ˜í”Œë¡œ)\n",
    "    print(\"\\n=== ì„ë² ë”© ë°ì´í„° ìƒ˜í”Œ ===\")\n",
    "    for i, item in enumerate(all_embedding_data[:3]):\n",
    "        print(f\"ìƒ˜í”Œ {i+1}:\")\n",
    "        print(f\"ID: {item['id']}\")\n",
    "        print(f\"Document: {item['document'][:100]}...\")\n",
    "        print(f\"Metadata: {item['metadata']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # 4. í†µê³„\n",
    "    print(f\"\\n=== í†µê³„ ===\")\n",
    "    print(f\"ì´ {len(all_embedding_data)}ê°œì˜ ì„ë² ë”© ê°ì²´ ìƒì„±\")\n",
    "    print(f\"ì´ìŠˆë‹¹ í‰ê·  {len(all_embedding_data)/len(issue_keys):.1f}ê°œì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í…\")\n",
    "    \n",
    "    # í‰ê·  ë¬¸ì„œ ê¸¸ì´\n",
    "    if all_embedding_data:\n",
    "        avg_doc_length = sum(len(item['document']) for item in all_embedding_data) / len(all_embedding_data)\n",
    "        print(f\"í‰ê·  ë¬¸ì„œ ê¸¸ì´: {avg_doc_length:.0f} ë¬¸ì\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
